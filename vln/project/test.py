"""
VLN (Vision-Language Navigation) Agent - è®°å¿†å¢å¼ºç‰ˆ
åŒ…å«åä¸ªæ ¸å¿ƒæ¨¡å—çš„å®Œæ•´å®ç° + å¤šå±‚æ¬¡è®°å¿†ç³»ç»Ÿ
"""
import habitat_sim
import cv2
import numpy as np
import torch
import json
import os
from PIL import Image
import random
from typing import Dict, List, Tuple, Optional, Any
from transformers import Qwen2VLForConditionalGeneration, AutoProcessor, BitsAndBytesConfig
from qwen_vl_utils import process_vision_info
from PIL import Image
from dataclasses import dataclass
from collections import deque
import habitat_sim
import matplotlib.pyplot as plt
import datetime
from scipy.spatial.transform import Rotation as R # ç”¨äºå¤„ç†æœå‘

# å¯¼å…¥å¢å¼ºè®°å¿†ç³»ç»Ÿ
import sys
sys.path.append('/home/ubuntu/YuanNav/vln/project')
from enhanced_memory_system import EnhancedMemorySystem, MemoryType

def draw_trajectory(agent, target_pos=None, save_path="vln_path_pro.png"):
    """ç»˜åˆ¶ä¸“ä¸šç‰ˆè½¨è¿¹å›¾ï¼šåŒ…å«å¢™å£è¾¹ç•Œã€1:1æ¯”ä¾‹å’Œæœå‘"""
    trajectory = agent.memory_mod.get_trajectory()
    if not trajectory:
        print("âŒ [ç»˜å›¾å¤±è´¥] è½¨è¿¹æ•°æ®ä¸ºç©º")
        return

    # 1. æå–è·¯å¾„ç‚¹ (X, Z)
    path_points = np.array([(e['perception']['spatial']['position'][0], 
                             e['perception']['spatial']['position'][2]) for e in trajectory])

    # 2. æå–æœå‘å‘é‡
    def get_heading_vector(rotation_quat):
        quat_list = [rotation_quat.x, rotation_quat.y, rotation_quat.z, rotation_quat.w]
        r = R.from_quat(quat_list)
        # Habitat åèˆªè§’åœ¨ Y è½´ï¼Œä½¿ç”¨ YXZ åºåˆ—ä¿®å¤ä¹‹å‰çš„æŠ¥é”™
        yaw = r.as_euler('YXZ')[0] 
        # è¿”å› (dx, dz) å‘é‡
        return np.array([np.sin(yaw), np.cos(yaw)])

    start_dir = get_heading_vector(trajectory[0]['perception']['spatial']['rotation'])
    end_dir = get_heading_vector(trajectory[-1]['perception']['spatial']['rotation'])

    # 3. ç»˜å›¾è®¾ç½®
    fig, ax = plt.subplots(figsize=(10, 10))
    
    # --- [å…³é”®å¢å¼º] ç»˜åˆ¶çœŸå®çš„åœ°å›¾è½®å»“ ---
    # é‡‡æ · 5000 ä¸ªå¯å¯¼èˆªç‚¹ï¼Œç”¨æå°çš„ç‚¹å’Œä½é€æ˜åº¦æç»˜å‡ºâ€œåœ°æ¿â€å½¢çŠ¶
    map_points = np.array([agent.pathfinder.get_random_navigable_point() for _ in range(5000)])
    ax.scatter(map_points[:, 0], map_points[:, 2], color='lightgray', s=1, alpha=0.3, label='Navigable Area')

    # ç»˜åˆ¶è¡Œèµ°è½¨è¿¹
    ax.plot(path_points[:, 0], path_points[:, 1], color='#1f77b4', linewidth=2.5, zorder=3, label='Agent Path')

    # ç»˜åˆ¶èµ·ç‚¹ï¼ˆç»¿ï¼‰å’Œç»ˆç‚¹ï¼ˆçº¢ï¼‰
    ax.scatter(path_points[0, 0], path_points[0, 1], color='green', s=100, marker='o', zorder=5)
    ax.scatter(path_points[-1, 0], path_points[-1, 1], color='red', s=100, marker='X', zorder=5)

    # ç»˜åˆ¶æœå‘ç®­å¤´ (Quiver)
    # scale è¶Šå°ç®­å¤´è¶Šé•¿
    ax.quiver(path_points[0, 0], path_points[0, 1], start_dir[0], start_dir[1], 
              color='green', scale=15, width=0.008, headwidth=5, zorder=6, label='Start Facing')
    ax.quiver(path_points[-1, 0], path_points[-1, 1], end_dir[0], end_dir[1], 
              color='red', scale=15, width=0.008, headwidth=5, zorder=6, label='End Facing')

    # 4. ç»˜åˆ¶ç›®æ ‡ (LAMP)
    if target_pos is not None:
        ax.scatter(target_pos[0], target_pos[2], color='#ff7f0e', s=250, marker='*', 
                   edgecolors='black', linewidths=1, zorder=7, label='Target (LAMP)')
        # è¿çº¿æ˜¾ç¤ºè¯¯å·®
        ax.plot([path_points[-1, 0], target_pos[0]], [path_points[-1, 1], target_pos[2]], 
                ':', color='gray', alpha=0.6)

    # --- [ç²¾ç»†åŒ–åæ ‡ç³»] ---
    ax.set_aspect('equal', adjustable='box') # å¼ºåˆ¶ 1:1 æ¯”ä¾‹
    ax.set_title(f"Visual Navigation Trajectory Analysis\nScene: Apartment | Steps: {len(path_points)}", fontsize=12)
    ax.set_xlabel("World X (meters)", fontsize=10)
    ax.set_ylabel("World Z (meters)", fontsize=10)
    ax.grid(True, linestyle='--', alpha=0.5)
    ax.legend(loc='upper left', bbox_to_anchor=(1, 1)) # å›¾ä¾‹æ”¾åœ¨å¤–é¢é˜²æ­¢é®æŒ¡åœ°å›¾
    
    plt.tight_layout()
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()
    print(f"ğŸ“ [ç³»ç»Ÿ] ä¼˜åŒ–ç‰ˆè½¨è¿¹å›¾å·²ä¿å­˜: {save_path}")

# ============================================================================
# æ¨¡å—1: æŒ‡ä»¤ (Instruction)agent.run(instruction, target_pos=target_pos)
# ============================================================================
class InstructionModule:
    """æŒ‡ä»¤æ¨¡å—ï¼šæ¥æ”¶å’Œå¤„ç†å¯¼èˆªæŒ‡ä»¤"""
    
    def __init__(self):
        self.current_instruction = None
        self.instruction_history = []
    
    def set_instruction(self, instruction: str):
        """è®¾ç½®å½“å‰å¯¼èˆªæŒ‡ä»¤"""
        self.current_instruction = instruction
        self.instruction_history.append(instruction)
        print(f"ğŸ“ [æŒ‡ä»¤æ¨¡å—] æ”¶åˆ°æŒ‡ä»¤: {instruction}")
        return instruction
    
    def get_instruction(self) -> Optional[str]:
        """è·å–å½“å‰æŒ‡ä»¤"""
        return self.current_instruction
    
    def parse_instruction(self, instruction: str) -> Dict[str, Any]:
        """è§£ææŒ‡ä»¤ï¼Œæå–å…³é”®ä¿¡æ¯"""
        return {
            "raw": instruction,
            "goal": instruction,
            "type": "navigation"
        }


# ============================================================================
# æ¨¡å—2: è§„åˆ’ (Planning)execute
# ============================================================================
class PlanningModule:
    """è§„åˆ’æ¨¡å—ï¼šåŸºäºæŒ‡ä»¤ç”Ÿæˆå¯¼èˆªè®¡åˆ’"""
    
    def __init__(self, llm_model=None, llm_processor=None):
        self.llm_model = llm_model
        self.llm_processor = llm_processor
        self.plan_history = []
    
    def generate_plan(self, instruction: Dict[str, Any]) -> Dict[str, Any]:
        """åŸºäºæŒ‡ä»¤ç”Ÿæˆå¯¼èˆªè®¡åˆ’"""
        print(f"ğŸ§  [è§„åˆ’æ¨¡å—] æ­£åœ¨ä¸ºæŒ‡ä»¤ç”Ÿæˆè®¡åˆ’: {instruction['goal']}")
        
        # ç®€å•è§„åˆ™è§„åˆ’ (å¯æ‰©å±•ä¸ºLLMè§„åˆ’)
        plan = {
            "steps": ["explore", "navigate", "search"],
            "strategy": "systematic_search",
            "max_steps": 100
        }
        
        self.plan_history.append(plan)
        print(f"âœ… [è§„åˆ’æ¨¡å—] è®¡åˆ’ç”Ÿæˆå®Œæˆ: {plan}")
        return plan


# ============================================================================
# æ¨¡å—3: è®¡åˆ’ (Plan)
# ============================================================================
@dataclass
class Plan:
    """è®¡åˆ’æ•°æ®ç»“æ„"""
    steps: List[str]
    strategy: str
    max_steps: int
    current_step: int = 0
    
    def get_current_step(self) -> str:
        """è·å–å½“å‰æ­¥éª¤"""
        if self.current_step < len(self.steps):
            return self.steps[self.current_step]
        return "complete"
    
    def advance_step(self):
        """æ¨è¿›åˆ°ä¸‹ä¸€æ­¥"""
        self.current_step += 1


# ============================================================================
# æ¨¡å—4: æ„ŸçŸ¥ + ç©ºé—´è¡¨è¾¾ (æ·±åº¦å¢å¼ºç‰ˆ)
# ============================================================================
class PerceptionModule:
    """æ„ŸçŸ¥æ¨¡å—ï¼šå¤„ç† RGB è§†è§‰ï¼ˆCLAHEå¢å¼ºï¼‰ã€æ·±åº¦ä¿¡æ¯ï¼ˆé¿éšœï¼‰å’Œç©ºé—´çŠ¶æ€"""
    
    def __init__(self, simulator=None):
        self.simulator = simulator
        self.observation_history = []
    
    def get_safe_distance(self, depth_obs: np.ndarray) -> float:
        """
        è®¡ç®—è§†é‡ä¸­å¿ƒåŒºåŸŸçš„æœ€å°æ·±åº¦å€¼
        :param depth_obs: Habitat æä¾›çš„æ·±åº¦è§‚æµ‹å€¼ (H, W)
        :return: å‰æ–¹éšœç¢ç‰©çš„æœ€è¿‘è·ç¦»ï¼ˆç±³ï¼‰
        """
        if depth_obs is None:
            return 999.0
            
        # 1. å®šä¹‰ä¸­å¿ƒæ„Ÿå…´è¶£åŒºåŸŸ (ROI: Region of Interest)
        # æˆ‘ä»¬å…³æ³¨å±å¹•ä¸­å¿ƒ 1/3 çš„åŒºåŸŸï¼Œé¿å…è¾¹ç¼˜å¹²æ‰°
        h, w = depth_obs.shape
        h_start, h_end = h // 3, 2 * h // 3
        w_start, w_end = w // 3, 2 * w // 3
        center_zone = depth_obs[h_start:h_end, w_start:w_end]
        
        # 2. è¿‡æ»¤æ‰æ— æ•ˆæ·±åº¦ï¼ˆHabitatä¸­0é€šå¸¸ä»£è¡¨è¶…è¿œæˆ–æ— æ•ˆï¼Œéœ€æ ¹æ®é…ç½®ç¡®å®šï¼‰
        # å¤§éƒ¨åˆ†æƒ…å†µä¸‹ç›´æ¥å–æœ€å°å€¼å³å¯ä»£è¡¨æœ€è¿‘éšœç¢ç‰©
        min_dist = np.min(center_zone)
        
        return float(min_dist)
    
    def perceive(self, agent_state=None) -> Dict[str, Any]:
        """æ‰§è¡Œå…¨æ¨¡æ€æ„ŸçŸ¥"""
        if self.simulator is None:
            return {"error": "simulator not initialized"}
        
        # è·å–æ‰€æœ‰ä¼ æ„Ÿå™¨è§‚æµ‹
        obs = self.simulator.get_sensor_observations()
        rgb_image = obs.get("color_sensor", None)
        depth_map = obs.get("depth_sensor", None)
        semantic_map = obs.get("semantic_sensor", None)
        
        # --- 1. RGB å›¾åƒå¤„ç† (CLAHE å¢å¼º) ---
        image_pil = None
        rgb_bgr_output = None

        if rgb_image is not None:
            # åŸºç¡€è½¬æ¢ (RGBA -> BGR)
            rgb_bgr = cv2.cvtColor(rgb_image, cv2.COLOR_RGBA2BGR)
            
            # CLAHE å¯¹æ¯”åº¦å—é™çš„è‡ªé€‚åº”ç›´æ–¹å›¾å‡è¡¡åŒ–
            lab = cv2.cvtColor(rgb_bgr, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))
            cl = clahe.apply(l)
            limg = cv2.merge((cl, a, b))
            enhanced_bgr = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)
            
            rgb_bgr_output = enhanced_bgr
            rgb_rgb = cv2.cvtColor(enhanced_bgr, cv2.COLOR_BGR2RGB)
            image_pil = Image.fromarray(rgb_rgb)
        
        # --- 2. æ·±åº¦ä¿¡æ¯å¤„ç† ---
        dist_to_obstacle = 999.0
        if depth_map is not None:
            dist_to_obstacle = self.get_safe_distance(depth_map)
        
        # --- 3. è¯­ä¹‰ä¿¡æ¯å¤„ç† (ç‰©ä½“æ£€æµ‹) ---
        detected_objects = []
        if semantic_map is not None:
            detected_objects = self._detect_objects_from_semantic(semantic_map)
        
        # --- 4. ç©ºé—´çŠ¶æ€æå– ---
        spatial_info = self._extract_spatial_info(agent_state)
        
        # å°è£…æ„ŸçŸ¥ç»“æœ
        perception = {
            "image": image_pil,           # ç”¨äº LLM æ€è€ƒçš„å¢å¼ºå›¾åƒ
            "image_array": rgb_bgr_output, # åŸå§‹æ•°ç»„ä¾› OpenCV ä½¿ç”¨
            "depth": dist_to_obstacle,    # å‰æ–¹éšœç¢ç‰©è·ç¦» (ç±³)
            "objects": detected_objects,  # æ£€æµ‹åˆ°çš„ç‰©ä½“åˆ—è¡¨
            "spatial": spatial_info,       # åæ ‡ä¸æœå‘
            "timestamp": len(self.observation_history)
        }
        
        self.memory_optimize(perception) # å¯é€‰ï¼šè®°å½•å†å²
        self.observation_history.append(perception)
        return perception
    
    def _detect_objects_from_semantic(self, semantic_map: np.ndarray) -> List[Dict[str, Any]]:
        """ä»è¯­ä¹‰å›¾ä¸­æ£€æµ‹ç‰©ä½“"""
        objects = []
        
        if semantic_map is None:
            return objects
        
        # è·å–åœºæ™¯ä¸­çš„æ‰€æœ‰ç‰©ä½“æ ‡ç­¾
        try:
            scene = self.simulator.get_active_scene()
            object_ids = np.unique(semantic_map)
            
            # è¿‡æ»¤æ‰èƒŒæ™¯æ ‡ç­¾ï¼ˆé€šå¸¸æ˜¯0ï¼‰
            object_ids = object_ids[object_ids > 0]
            
            for obj_id in object_ids:
                # è®¡ç®—è¯¥ç‰©ä½“åœ¨å›¾åƒä¸­çš„å æ¯”
                mask = (semantic_map == obj_id)
                area = np.sum(mask)
                total_pixels = semantic_map.size
                area_ratio = area / total_pixels
                
                # åªè®°å½•å æ¯”è¶…è¿‡1%çš„ç‰©ä½“
                if area_ratio > 0.01:
                    # å°è¯•è·å–ç‰©ä½“åç§°
                    obj_name = f"object_{obj_id}"
                    try:
                        obj = scene.get_object_by_id(obj_id)
                        if hasattr(obj, 'category_name'):
                            obj_name = obj.category_name
                        elif hasattr(obj, 'semantic_id'):
                            obj_name = f"semantic_{obj.semantic_id}"
                    except:
                        pass
                    
                    objects.append({
                        "type": obj_name,
                        "id": int(obj_id),
                        "area_ratio": float(area_ratio),
                        "confidence": min(1.0, area_ratio * 10)  # æ ¹æ®é¢ç§¯ä¼°ç®—ç½®ä¿¡åº¦
                    })
        except Exception as e:
            # å¦‚æœè¯­ä¹‰è§£æå¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨
            pass
        
        return objects

    def _extract_spatial_info(self, agent_state) -> Dict[str, Any]:
        """æå– Agent å½“å‰ä½ç½®å’Œæ—‹è½¬"""
        if agent_state is None:
            return {"position": None, "rotation": None, "has_position": False}
        return {
            "position": agent_state.position.tolist(),
            "rotation": agent_state.rotation,
            "has_position": True
        }

    def memory_optimize(self, perception: Dict):
        """ç®€å•çš„æ—¥å¿—è®°å½•ï¼Œé˜²æ­¢å†…å­˜ä¸­å­˜å‚¨è¿‡å¤§çš„è§‚æµ‹å†å²"""
        if len(self.observation_history) % 20 == 0 and len(self.observation_history) > 0:
            print(f"ğŸ‘ï¸ [æ„ŸçŸ¥ç³»ç»Ÿ] æ­¥æ•°: {perception['timestamp']}, å½“å‰å‰æ–¹æ·±åº¦: {perception['depth']:.2f}m")


# ============================================================================
# æ¨¡å—5: è®°å¿† (Memory) - å¢å¼ºç‰ˆ
# ============================================================================
class MemoryModule:
    """è®°å¿†æ¨¡å—ï¼šé›†æˆå¢å¼ºè®°å¿†ç³»ç»Ÿï¼Œæ”¯æŒå¤šå±‚æ¬¡è®°å¿†"""
    
    def __init__(self, max_memory_size=100):
        # ä½¿ç”¨å¢å¼ºè®°å¿†ç³»ç»Ÿæ›¿ä»£ç®€å•çš„é˜Ÿåˆ—
        self.enhanced_memory = EnhancedMemorySystem(
            max_episodic=200, 
            max_semantic=1000, 
            max_spatial=500
        )
        
        # ä¿æŒå‘åå…¼å®¹çš„æ¥å£
        self.memory = deque(maxlen=max_memory_size)
        self.last_result = "partial"  # ç”¨äºé‡è¦æ€§è¯„ä¼°
        
    def store(self, perception: Dict, action: str, reward: float = 0.0) -> Dict[str, Any]:
        """å­˜å‚¨ä¸€æ­¥çš„ç»éªŒ - åŒæ—¶å­˜å‚¨åˆ°ç®€å•è®°å¿†å’Œå¢å¼ºè®°å¿†ç³»ç»Ÿ
        
        Returns:
            Dict: åŒ…å«ç‰©ä½“å…³è”ä¿¡æ¯ {'associations': List[Dict]}
        """
        step = len(self.memory)
        associations = []  # å­˜å‚¨ç‰©ä½“å…³è”ä¿¡æ¯
        
        # å­˜å‚¨åˆ°ç®€å•è®°å¿†ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        memory_entry = {
            "perception": perception,
            "action": action,
            "step": step
        }
        self.memory.append(memory_entry)
        
        # å­˜å‚¨åˆ°å¢å¼ºè®°å¿†ç³»ç»Ÿ
        if perception.get('objects'):
            for obj in perception['objects']:
                if obj.get('type') and obj.get('confidence', 0) > 0.5:
                    # å­˜å‚¨è¯­ä¹‰è®°å¿†
                    association_info = self.enhanced_memory.store_semantic(
                        object_type=obj['type'],
                        object_id=f"{obj['type']}_{step}_{random.randint(1000, 9999)}",
                        location=tuple(perception.get('position', [0, 0, 0])) if perception.get('position') else None,
                        properties={'confidence': obj.get('confidence', 0), 'bbox': obj.get('bbox', [])},
                        confidence=obj.get('confidence', 0)
                    )
                    # è®°å½•å…³è”ä¿¡æ¯
                    associations.append({
                        'object_type': obj['type'],
                        'is_new': association_info['is_new'],
                        'object_id': association_info['object_id'],
                        'distance': association_info['distance']
                    })
        
        # å­˜å‚¨ç©ºé—´è®°å¿†
        if perception.get('position') and perception.get('rotation'):
            self.enhanced_memory.store_spatial(
                position=tuple(perception['position']),
                rotation=tuple(perception['rotation']),
                region_id=None,  # è®©ç³»ç»Ÿè‡ªåŠ¨åˆ†ç±»
                landmarks=[obj['type'] for obj in perception.get('objects', []) if obj.get('confidence', 0) > 0.7]
            )
        
        # å­˜å‚¨æƒ…æ™¯è®°å¿†
        importance = self._calculate_importance(action, self.last_result, step)
        self.enhanced_memory.store_episodic(
            step=step,
            action=action,
            perception=perception,
            result=self.last_result,
            importance=importance
        )
        
        print(f"ğŸ’¾ [å¢å¼ºè®°å¿†æ¨¡å—] å­˜å‚¨ç¬¬ {step} æ­¥ç»éªŒ (é‡è¦æ€§: {importance:.2f})")
        
        return {'associations': associations}
    
    def retrieve(self, query: str = None, k: int = 5) -> List[Dict]:
        """æ£€ç´¢è®°å¿† - å¢å¼ºç‰ˆæ£€ç´¢èƒ½åŠ›"""
        if query is None:
            # é»˜è®¤æ£€ç´¢æœ€è¿‘çš„è®°å¿†
            return list(self.memory)[-k:]
        
        # ä½¿ç”¨å¢å¼ºè®°å¿†ç³»ç»Ÿè¿›è¡Œæ™ºèƒ½æ£€ç´¢
        episodic_results = self.enhanced_memory.retrieve_relevant("episodic", query, k=k//2)
        semantic_results = self.enhanced_memory.retrieve_relevant("semantic", query, k=k//2)
        
        # è½¬æ¢æ ¼å¼ä»¥ä¿æŒå…¼å®¹æ€§
        combined_results = []
        
        # æ·»åŠ æƒ…æ™¯è®°å¿†
        for episode in episodic_results:
            combined_results.append({
                "perception": episode.perception,
                "action": episode.action,
                "step": episode.step,
                "importance": episode.importance,
                "result": episode.result
            })
        
        # æ·»åŠ è¯­ä¹‰è®°å¿†
        for semantic in semantic_results:
            combined_results.append({
                "object_type": semantic.object_type,
                "location": semantic.location,
                "confidence": semantic.confidence,
                "last_seen_step": semantic.last_seen_step
            })
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ç›¸å…³è®°å¿†ï¼Œè¿”å›æœ€è¿‘çš„è®°å¿†
        if not combined_results:
            return list(self.memory)[-k:]
            
        return combined_results[:k]
    
    def get_trajectory(self) -> List[Dict]:
        """è·å–è½¨è¿¹ - å…¼å®¹åŸæ¥å£"""
        return list(self.memory)
    
    def get_spatial_context(self, current_position: Tuple[float, float, float]) -> Dict[str, Any]:
        """è·å–ç©ºé—´ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        return self.enhanced_memory.get_spatial_context(current_position)
    
    def get_semantic_context(self, object_type: str = None) -> Dict[str, Any]:
        """è·å–è¯­ä¹‰ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        return self.enhanced_memory.get_semantic_context(object_type)
    
    def get_navigation_guidance(self, target_type: str = "lamp") -> Dict[str, Any]:
        """è·å–å¯¼èˆªæŒ‡å¯¼"""
        return self.enhanced_memory.get_navigation_guidance(target_type)
    
    def set_last_result(self, result: str):
        """è®¾ç½®ä¸Šä¸€æ­¥çš„ç»“æœï¼Œç”¨äºé‡è¦æ€§è¯„ä¼°"""
        self.last_result = result
    
    def _calculate_importance(self, action: str, result: str, step: int) -> float:
        """è®¡ç®—è®°å¿†é‡è¦æ€§"""
        importance = 0.5  # åŸºç¡€é‡è¦æ€§
        
        # æ ¹æ®ç»“æœè°ƒæ•´é‡è¦æ€§
        if result == "success":
            importance += 0.3
        elif result == "failure":
            importance += 0.2
        
        # æ ¹æ®åŠ¨ä½œè°ƒæ•´é‡è¦æ€§
        if "stop" in action:
            importance += 0.1
        elif "turn" in action:
            importance += 0.05
        
        # æ ¹æ®æ­¥æ•°è°ƒæ•´ï¼ˆè¾ƒæ–°çš„è®°å¿†æ›´é‡è¦ï¼‰
        importance += min(0.2, step * 0.001)
        
        return min(1.0, importance)
    
    def consolidate_memory(self):
        """è®°å¿†å·©å›º"""
        self.enhanced_memory.consolidate_memory()
    
    def export_memory(self, file_path: str):
        """å¯¼å‡ºè®°å¿†æ•°æ®"""
        self.enhanced_memory.export_memory(file_path)
    
    def get_memory_summary(self) -> Dict[str, Any]:
        """è·å–è®°å¿†æ‘˜è¦"""
        summary = self.enhanced_memory.get_memory_summary()
        summary.update({
            'simple_memory_size': len(self.memory),
            'backward_compatible': True
        })
        return summary


# ============================================================================
# æ¨¡å—6: è·¨æ¨¡æ€å¯¹é½ (ä¿®å¤ Action è§£æ Bug)ExecutionModule
# ============================================================================
class CrossModalAlignmentModule:
    def __init__(self, model=None, processor=None, memory_module=None):
        self.model = model
        self.processor = processor
        self.memory_module = memory_module  # é›†æˆè®°å¿†æ¨¡å—

    def think(self, perception: Dict, instruction: str, memory: List[Dict] = None, 
              collision_warning: bool = False, step_count: int = 0) -> Dict[str, Any]:
        if self.model is None: return {"action": "move_forward", "reasoning": "default"}
        
        image = perception.get("image")
        if image is None: return {"action": "stop", "reasoning": "blind"}
        
        # === [ä¿®å¤] ç›´æ¥ä½¿ç”¨å¤–éƒ¨ä¼ å…¥çš„ step_countï¼Œä¸è¢« memory è¦†ç›– ===
        current_step = step_count 
        
        # === [è®°å¿†å¢å¼º] è·å–ä¸Šä¸‹æ–‡ä¿¡æ¯ ===
        spatial_context = {}
        semantic_context = {}
        navigation_guidance = {}
        
        if self.memory_module:
            # è·å–ç©ºé—´ä¸Šä¸‹æ–‡
            if perception.get('position'):
                spatial_context = self.memory_module.get_spatial_context(perception['position'])
            
            # è·å–è¯­ä¹‰ä¸Šä¸‹æ–‡ï¼ˆä¸“æ³¨å°ç¯ç›¸å…³ï¼‰
            semantic_context = self.memory_module.get_semantic_context("lamp")
            
            # è·å–å¯¼èˆªæŒ‡å¯¼
            navigation_guidance = self.memory_module.get_navigation_guidance("lamp")
        
        status_prompt = ""
        if collision_warning:
            status_prompt = "\n[âš ï¸ WARNING: STUCK! Last move hit a wall. TURN to find open space!]"
        
        # === [è®°å¿†å¢å¼º] æ„å»ºè®°å¿†æ„ŸçŸ¥çš„æç¤ºè¯ ===
        memory_context = self._build_memory_context(spatial_context, semantic_context, navigation_guidance)
        
        text_prompt = f"""Task: Find the LAMP and STOP when you see it clearly.

Current Step: {current_step} (Max: 300) {status_prompt}

{memory_context}

IMPORTANT INSTRUCTIONS:
1. If you see a lamp clearly in your view, you MUST output "Action: stop" immediately.
2. DO NOT keep turning if you see the lamp 

First, describe what you see and your reasoning. Then, output your action.
Format:
Reasoning: [your reasoning here]
Action: [move_forward / turn_left / turn_right / stop / move_backward]"""

        messages = [{"role": "user", "content": [{"type": "image", "image": image}, {"type": "text", "text": text_prompt}]}]
        text = self.processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
        image_inputs, video_inputs = process_vision_info(messages)
        inputs = self.processor(text=[text], images=image_inputs, videos=video_inputs, padding=True, return_tensors="pt").to(self.model.device)
        
        with torch.no_grad():
            generated_ids = self.model.generate(**inputs, max_new_tokens=128)
        
        output_text = self.processor.batch_decode(generated_ids, skip_special_tokens=True)[0]
        pure_output = output_text.replace(text, "").strip() if text in output_text else output_text
        
        # åªæå–æ¨¡å‹çš„æ¨ç†éƒ¨åˆ†ï¼ˆ"assistant" ä¹‹åçš„å†…å®¹ï¼‰
        if "assistant" in pure_output:
            pure_output = pure_output.split("assistant")[-1].strip()
        
        # æå–æ¨ç†éƒ¨åˆ†ï¼ˆ"Reasoning:" å’Œ "Action:" ä¹‹é—´çš„å†…å®¹ï¼‰
        reasoning = pure_output
        action = "move_forward"  # é»˜è®¤åŠ¨ä½œ
        
        if "Reasoning:" in pure_output and "Action:" in pure_output:
            parts = pure_output.split("Action:")
            reasoning = parts[0].replace("Reasoning:", "").strip()
            action_part = parts[1].strip().split()[0] if parts[1].strip() else "move_forward"
            action = action_part.lower()
        elif "Action:" in pure_output:
            # å¦‚æœåªæœ‰Actionï¼Œæå–åŠ¨ä½œ
            parts = pure_output.split("Action:")
            reasoning = parts[0].strip()
            action_part = parts[1].strip().split()[0] if parts[1].strip() else "move_forward"
            action = action_part.lower()
        else:
            # å¦‚æœæ²¡æœ‰æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨æ•´ä¸ªè¾“å‡º
            reasoning = pure_output
            action = self._extract_action(pure_output)
        
        print(f"ğŸ§  [CoTæ¨ç†] Step {current_step}: {reasoning}")
        print(f"ğŸ¯ [åŠ¨ä½œé€‰æ‹©] Step {current_step}: {action}")
        
        return {"action": action, "reasoning": reasoning}
    
    def _build_memory_context(self, spatial_context: Dict, semantic_context: Dict, navigation_guidance: Dict) -> str:
        """æ„å»ºè®°å¿†æ„ŸçŸ¥çš„ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        context_parts = []
        
        # ç©ºé—´ä¸Šä¸‹æ–‡
        if spatial_context:
            explored_regions = spatial_context.get('explored_regions', 0)
            exploration_progress = spatial_context.get('exploration_progress', 0)
            context_parts.append(f"[SPATIAL MEMORY] Explored {explored_regions} regions, {exploration_progress:.1%} completion")
            
            # æ·»åŠ é™„è¿‘åœ°æ ‡ä¿¡æ¯
            nearby_landmarks = spatial_context.get('nearby_landmarks', [])
            if nearby_landmarks:
                landmark_names = [landmark.region_id for landmark in nearby_landmarks[:3]]
                context_parts.append(f"Nearby landmarks: {', '.join(landmark_names)}")
        
        # è¯­ä¹‰ä¸Šä¸‹æ–‡
        if semantic_context:
            known_objects = semantic_context.get('known_objects', 0)
            if known_objects > 0:
                context_parts.append(f"[SEMANTIC MEMORY] Previously seen {known_objects} objects")
                
            # æ·»åŠ é«˜ç½®ä¿¡åº¦ç‰©ä½“
            high_confidence = semantic_context.get('high_confidence_objects', [])
            if high_confidence:
                object_types = [obj.object_type for obj in high_confidence[:3]]
                context_parts.append(f"High-confidence objects: {', '.join(object_types)}")
        
        # å¯¼èˆªæŒ‡å¯¼
        if navigation_guidance:
            target_found = navigation_guidance.get('target_found', False)
            if target_found:
                confidence = navigation_guidance.get('confidence', 0)
                context_parts.append(f"[NAVIGATION GUIDANCE] Target likely found with {confidence:.1%} confidence")
            else:
                search_strategy = navigation_guidance.get('search_strategy', 'exploration')
                context_parts.append(f"[NAVIGATION GUIDANCE] Search strategy: {search_strategy}")
        
        if context_parts:
            return "\n".join(context_parts) + "\n"
        else:
            return "[MEMORY] Starting fresh exploration\n"

    def _extract_action(self, text: str) -> str:
        text_lower = text.lower()
        # æå– Action éƒ¨åˆ†
        if "action:" in text_lower:
            action_part = text_lower.split("action:")[-1].strip()
        else:
            lines = text_lower.strip().split('\n')
            action_part = lines[-1] if lines else ""

        # --- [ç­–ç•¥å¹²é¢„] é—¨æ¡†ä¼˜å…ˆçº§ä¸æ¨è¿›åŠ¨åŠ› ---
        # å‡å°‘é—¨æ¡†çš„å¼ºåˆ¶å¹²é¢„ï¼Œè®©æ¨¡å‹æœ‰æ›´å¤šè‡ªä¸»å†³ç­–æƒ
        is_exploring_door = any(word in text_lower for word in ["doorway", "entrance", "enter", "another room", "opening"])
        
        # åªåœ¨æ²¡æœ‰æ˜ç¡®ç›®æ ‡ï¼ˆå°ç¯ï¼‰æ—¶æ‰åº”ç”¨é—¨æ¡†å¼•å¯¼
        has_lamp = any(word in text_lower for word in ["lamp", "light", "shade"])
        
        if is_exploring_door and "stop" not in action_part and not has_lamp:
            if "forward" not in action_part:
                print("âœ¨ [è¯­ä¹‰å¼•å¯¼] æ£€æµ‹åˆ°é—¨æ¡†ä¸”æ— ç›®æ ‡ï¼Œä¿®æ­£åŠ¨ä½œï¼šmove_forward ä»¥å¢å¼ºæ¢ç´¢ã€‚")
                return "move_forward"

        # --- [å®¡æŸ¥æœºåˆ¶] ç›®æ ‡ç‰©æ ¡éªŒ (ç”±æ²™å‘æ”¹ä¸ºå°ç¯) ---
        # æ£€æŸ¥æ¨ç†ä¸­æ˜¯å¦æ˜ç¡®æåˆ°äº† lamp
        has_lamp_mentioned = any(word in text_lower for word in ["lamp", "light", "shade"])
        is_visible = any(word in text_lower for word in ["visible", "see", "found", "center", "front", "close", "near", "looking", "view"])
        is_located = any(word in text_lower for word in ["located", "near", "behind", "next to", "beside"])
        
        # å¦‚æœæ¨ç†ä¸­æ˜ç¡®æåˆ°çœ‹åˆ°äº† lampï¼Œä½† action ä¸æ˜¯ stopï¼Œåˆ™å¼ºåˆ¶ä¿®æ­£ä¸º stop
        if has_lamp_mentioned and (is_visible or is_located) and "stop" not in action_part:
            print(f"ğŸ¯ [å¼ºåˆ¶ä¿®æ­£] æ¨ç†ä¸­æåˆ° lampï¼Œä½† action ä¸æ˜¯ stopï¼Œå¼ºåˆ¶ä¿®æ­£ä¸º stopï¼")
            return "stop"
        
        if "stop" in action_part:
            # è¿›ä¸€æ­¥æ”¾å®½ï¼šåªè¦æ¨ç†ä¸­æåˆ°ç›®æ ‡ç‰©ï¼Œå°±å…è®¸åœæ­¢
            if has_lamp_mentioned or is_visible:
                return "stop"
            else:
                # å¦‚æœæ¨ç†å†…å®¹å¾ˆçŸ­ä¸”åªæœ‰stopï¼Œä¹Ÿå…è®¸åœæ­¢ï¼ˆå¯èƒ½æ˜¯æ¨¡å‹ç›´æ¥è¾“å‡ºstopï¼‰
                if len(text_lower.strip()) < 50 and "stop" in text_lower:
                    return "stop"
                print("ğŸ›¡ï¸ [å®¡æŸ¥é©³å›] è§†è§‰è¯æ®ä¸è¶³ï¼Œå¼ºåˆ¶è½¬å‘æ¢æµ‹ã€‚")
                return "turn_left"

        if "backward" in action_part: return "move_backward"
        if "left" in action_part: return "turn_left"
        if "right" in action_part: return "turn_right"
        return "move_forward"

# ============================================================================
# æ¨¡å—7: å†³ç­– (Decision Making)
# ============================================================================
class DecisionModule:
    def __init__(self):
        self.decision_history = []
        self.action_space = ["move_forward", "turn_left", "turn_right", "stop", "move_backward"]
        self.last_image_gray = None # ç”¨äºå­˜å‚¨ä¸Šä¸€å¸§çš„ç°åº¦å›¾
        self.last_reasoning = None # ç”¨äºå­˜å‚¨ä¸Šä¸€å¸§çš„æ¨ç†
        self.same_reasoning_count = 0 # æ¨ç†é‡å¤è®¡æ•°

    def decide(self, llm_output: Dict, current_image: Image = None) -> str:
        action = llm_output.get("action", "move_forward")
        reasoning = llm_output.get("reasoning", "")
        
        # --- [ç­–ç•¥ä»‹å…¥] æ¨ç†é‡å¤æ£€æµ‹ ---
        if self.last_reasoning is not None:
            # è®¡ç®—æ¨ç†ç›¸ä¼¼åº¦ï¼ˆç®€å•çš„å­—ç¬¦ä¸²æ¯”è¾ƒï¼‰
            if reasoning == self.last_reasoning:
                self.same_reasoning_count += 1
                print(f"âš ï¸ [æ¨ç†é‡å¤] æ£€æµ‹åˆ°ç›¸åŒæ¨ç†ï¼Œè¿ç»­æ¬¡æ•°: {self.same_reasoning_count}")
                
                # å¦‚æœæ¨ç†è¿ç»­ 5 æ¬¡éƒ½ä¸€æ ·ï¼Œå¼ºåˆ¶è½¬å‘
                if self.same_reasoning_count >= 5:
                    print("ğŸ”„ [å¼ºåˆ¶è½¬å‘] æ¨ç†é‡å¤è¿‡å¤šï¼Œæ‰§è¡Œ 180Â° è½¬å‘ï¼")
                    self.same_reasoning_count = 0
                    return "turn_left"  # å¼ºåˆ¶è½¬å‘
            else:
                self.same_reasoning_count = 0
        
        self.last_reasoning = reasoning
        
        # --- [ç­–ç•¥ä»‹å…¥] è§†è§‰åœæ»æ£€æµ‹ ---
        if current_image is not None:
            # å°†å½“å‰å›¾è½¬ä¸ºç°åº¦å¹¶ç¼©å°ï¼Œè®¡ç®—å·®å¼‚
            curr_gray = np.array(current_image.convert('L').resize((64, 64)))
            
            if self.last_image_gray is not None:
                # è®¡ç®—å‡æ–¹è¯¯å·® (MSE)
                mse = np.mean((self.last_image_gray - curr_gray) ** 2)
                
                # é™ä½é˜ˆå€¼ï¼šå¦‚æœ MSE æå°ï¼ˆ< 2.0ï¼‰ï¼Œè¯´æ˜ç”»é¢å‡ ä¹æ²¡å˜
                if mse < 2.0:
                    print(f"ğŸ•µï¸ [å†³ç­–å¹²é¢„] æ£€æµ‹åˆ°ç”»é¢åœæ» (MSE: {mse:.2f})ï¼Œå¼ºåˆ¶æ‰§è¡Œè½¬å‘é€ƒé€¸ï¼")
                    action = random.choice(["turn_left", "turn_right"])
            
            self.last_image_gray = curr_gray # æ›´æ–°ç¼“å­˜
        else:
            # å¦‚æœæ˜¯æ—‹è½¬åŠ¨ä½œï¼Œé‡ç½®ç¼“å­˜é˜²æ­¢è¯¯å·®
            self.last_image_gray = None

        # åŸæœ‰çš„é€»è¾‘ï¼šé˜²æ­¢åå¤æ¨ªè·³
        if len(self.decision_history) >= 2:
            last_1 = self.decision_history[-1]['action']
            if last_1 == "move_backward" and action == "move_forward":
                action = random.choice(["turn_left", "turn_right"])

        self.decision_history.append({"action": action})
        return action

# ============================================================================
# æ¨¡å—8: æ‰§è¡Œ (Execution)_extract_action
# ============================================================================
class ExecutionModule:
    def __init__(self, simulator=None):
        self.simulator = simulator
    
    def execute(self, action: str) -> Dict[str, Any]:
        print(f"âš¡ [æ‰§è¡Œæ¨¡å—] æ­£åœ¨æ‰§è¡Œ: {action}")
        if self.simulator is None: return {"success": False}
        
        try:
            if action == "move_forward":
                # === [ä¿®æ”¹è¿™é‡Œ] æ”¹å›å•æ­¥æ¨¡å¼ (0.25m) ===
                self.simulator.step("move_forward")
                # self.simulator.step("move_forward") # <--- æ³¨é‡Šæ‰æˆ–åˆ é™¤è¿™è¡Œï¼Œä¸è¦è¿èµ°ä¸¤æ­¥ï¼
            
            elif action == "move_backward":
                # åé€€ä¿æŒä¸¤æ­¥æˆ–è€…æ”¹æˆä¸€æ­¥éƒ½å¯ä»¥ï¼Œå»ºè®®ä¿æŒä¸¤æ­¥ä»¥ä¾¿å¿«é€Ÿè„±å›°
                self.simulator.step("move_backward")
                self.simulator.step("move_backward")
                
            elif action in ["turn_left", "turn_right"]:
                self.simulator.step(action)
            
            elif action == "stop":
                pass # è¿™é‡Œçš„ stop æ˜¯é€»è¾‘åœæ­¢ï¼Œä¸éœ€è¦ç‰©ç†åŠ¨ä½œ
                
            return {"success": True, "action": action}
        except Exception as e:
            print(f"âŒ æ‰§è¡Œé”™è¯¯: {e}")
            # å¦‚æœåŠ¨ä½œä¸å­˜åœ¨ (æ¯”å¦‚æ‰“é”™å­—)ï¼Œä¸è¦è®©ç¨‹åºå´©ï¼Œè¿”å›å¤±è´¥å³å¯
            return {"success": False}

# ============================================================================
# æ¨¡å—9: å¾ªç¯ (Loop/Cycle)
# ============================================================================
class LoopController:
    """å¾ªç¯æ§åˆ¶æ¨¡å—ï¼šç®¡ç†å¾ªç¯"""
    def __init__(self, max_steps=100):
        self.max_steps = max_steps
        self.current_step = 0
        self.should_stop = False
    
    def should_continue(self) -> bool:
        if self.should_stop: return False
        if self.current_step >= self.max_steps: return False
        return True
    
    def advance_step(self):
        self.current_step += 1
        print(f"ğŸ”„ [å¾ªç¯æ§åˆ¶] ç¬¬ {self.current_step}/{self.max_steps} æ­¥")
    
    def stop(self):
        self.should_stop = True
        print("ğŸ›‘ [å¾ªç¯æ§åˆ¶] æ”¶åˆ°åœæ­¢ä¿¡å·")
    
    def reset(self):
        self.current_step = 0
        self.should_stop = False


# ============================================================================
# æ¨¡å—10: æ‰“åˆ† (Scoring) - ç¨å¾®å¢å¼ºæ—¥å¿—run
# ============================================================================
class ScoringModule:
    """æ‰“åˆ†æ¨¡å—ï¼šè¯„ä¼°å¯¼èˆªæ€§èƒ½"""
    def __init__(self):
        self.scores = []
    
    def score(self, trajectory: List[Dict], goal_reached: bool = False,
              start_position: List[float] = None, 
              target_position: List[float] = None) -> Dict[str, Any]:
        
        # === SR (Success Rate) ===
        SR = 1.0 if goal_reached else 0.0
        
        # === è®¡ç®—å®é™…è·¯å¾„é•¿åº¦ ===
        actual_path_length = self._calculate_path_length(trajectory)
        
        # === è®¡ç®—æœ€ä¼˜è·¯å¾„é•¿åº¦ (å¦‚æœæœ‰çœŸå€¼ç›®æ ‡) ===
        optimal_path_length = 0.0
        if start_position is not None and target_position is not None:
            # è¿™é‡Œç”¨æ¬§æ°è·ç¦»åšè¿‘ä¼¼ï¼Œå¦‚æœæœ‰ pathfinder æœ€å¥½ç”¨ geodesic
            optimal_path_length = np.linalg.norm(np.array(start_position) - np.array(target_position))
        
        # === SPL ===
        if goal_reached and actual_path_length > 0 and optimal_path_length > 0:
            SPL = SR * (optimal_path_length / max(actual_path_length, optimal_path_length))
        else:
            SPL = 0.0
        
        score_result = {
            "SR": SR,
            "SPL": SPL,
            "goal_reached": goal_reached,
            "steps": len(trajectory),
            "path_length": actual_path_length
        }
        
        self.scores.append(score_result)
        if optimal_path_length > 0:
            print(f"   - è¯†åˆ«æ­¥æ•°: {len(trajectory)}")
            print(f"   - å®é™…è¡Œèµ°è·ç¦»: {actual_path_length:.2f} ç±³")
            if goal_reached:
                print(f"   - è¯†åˆ«æˆåŠŸï¼šä»£ç†æ‰¾åˆ°å°ç¯å¹¶åœæ­¢")
            else:
                print(f"   - è¯†åˆ«å¤±è´¥ï¼šä»£ç†æœªæ‰¾åˆ°å°ç¯")
        return score_result
    
    def _calculate_path_length(self, trajectory: List[Dict]) -> float:
        total = 0.0
        for i in range(len(trajectory) - 1):
            p1 = trajectory[i]['perception']['spatial']['position']
            p2 = trajectory[i+1]['perception']['spatial']['position']
            if p1 is not None and p2 is not None:
                total += np.linalg.norm(np.array(p1) - np.array(p2))
        return total


# ============================================================================
# æ ¸å¿ƒé›†æˆ: VLN Agent (æ•´åˆæ‰€æœ‰æ¨¡å—)self.loop_controller
# ============================================================================
class VLNAgent:
    def __init__(self, scene_path: str, model_path: str):
        print("\nğŸš€ [System] åˆå§‹åŒ– VLN Agent (è·ç¦»å¢å¼ºç‰ˆ)...")
        self.simulator = self._init_simulator(scene_path)
        self.model, self.processor = self._init_llm(model_path)
        
        # æ¨¡å—å®ä¾‹åŒ–
        self.instruction_mod = InstructionModule()
        self.planning_mod = PlanningModule()
        self.perception_mod = PerceptionModule(simulator=self.simulator)
        self.memory_mod = MemoryModule(max_memory_size=50)
        # ä¼ é€’memory_moduleç»™CrossModalAlignmentModule
        self.alignment_mod = CrossModalAlignmentModule(
            model=self.model, 
            processor=self.processor, 
            memory_module=self.memory_mod
        )
        self.decision_mod = DecisionModule()
        self.execution_mod = ExecutionModule(simulator=self.simulator)
        self.loop_controller = LoopController(max_steps=50) # ä¿®æ”¹æœ€å¤§æ­¥æ•°ä¸º50
        self.scoring_mod = ScoringModule()
        
        # è·¯å¾„æŸ¥æ‰¾å™¨ (ç”¨äºè®¡ç®—è·ç¦»ï¼Œä¸å‚ä¸ Agent å†³ç­–)
        self.pathfinder = self.simulator.pathfinder
        
        # çŠ¶æ€å˜é‡
        self.verified = False  # è§†è§’éªŒè¯çŠ¶æ€
        self.centered = False  # å±…ä¸­è°ƒæ•´çŠ¶æ€
        self.approaching_lamp = False  # æ˜¯å¦æ­£åœ¨æ¥è¿‘lamp
        
        # å…¨å±€ä½ç½®è½¨è¿¹ï¼ˆç”¨äºæ™ºèƒ½æ¢ç´¢ï¼‰
        self.position_history = []  # è®°å½•æ‰€æœ‰è®¿é—®è¿‡çš„ä½ç½®
        self.last_position = None  # ä¸Šä¸€æ¬¡ä½ç½®
        self.position_stuck_count = 0  # ä½ç½®å¡ä½è®¡æ•°
        self.unexplored_regions = []  # æœªæ¢ç´¢åŒºåŸŸ
        
        # åŒå‘æ—‹è½¬æ§åˆ¶
        self.last_turn_direction = None  # ä¸Šä¸€æ¬¡è½¬å‘æ–¹å‘: "left" æˆ– "right"

    def scan_surroundings(self):
        print("ğŸ”„ [ç­–ç•¥] å¯åŠ¨ 360Â° å…¨æ™¯æ‰«æ...")
        views = []
        # æ—‹è½¬ 12 æ¬¡ï¼Œæ¯æ¬¡ 30 åº¦ï¼Œè¦†ç›– 360 åº¦
        for _ in range(12):
            self.simulator.step("turn_left")
            obs = self.simulator.get_sensor_observations()
            # è®°å½•æ¯ä¸€å¸§å›¾åƒï¼Œåç»­å¯ä»¥æ‹¼æ¥æˆ–è®© LLM æ‰¹é‡å¤„ç†
            views.append(self.perception_mod.perceive())
        
        # å°†å¤šå¼ å›¾æ‹¼æ¥æˆä¸€å¼ é•¿æ¡å›¾ï¼ˆå…¨æ™¯å›¾ï¼‰ä¼ ç»™ Qwen2-VL
        panorama = self._stitch_images([v["image"] for v in views])
        return panorama

    def _init_simulator(self, scene_path: str):
        print(f"ğŸ—ï¸ [System] æ­£åœ¨åŠ è½½åœºæ™¯å¹¶é…ç½®åŠ¨ä½œç©ºé—´...")
        sim_cfg = habitat_sim.SimulatorConfiguration()
        sim_cfg.scene_id = scene_path
        sim_cfg.gpu_device_id = 0
        # === [ä¿®æ”¹ç‚¹ 1] è®¾ç½®éšæœºç§å­ ===
        sim_cfg.random_seed = random.randint(0, 1000000) 
        # =============================
        
        agent_cfg = habitat_sim.agent.AgentConfiguration()
        # ... (åç»­ä¼ æ„Ÿå™¨å’ŒåŠ¨ä½œç©ºé—´é…ç½®ä¿æŒä¸å˜)
        
        # 1. é…ç½®ä¼ æ„Ÿå™¨
        rgb_sensor = habitat_sim.CameraSensorSpec()
        rgb_sensor.uuid = "color_sensor"
        rgb_sensor.sensor_type = habitat_sim.SensorType.COLOR
        rgb_sensor.resolution = [480, 640]
        rgb_sensor.position = [0.0, 1.2, 0.0]
        agent_cfg.sensor_specifications = [rgb_sensor]
        depth_sensor = habitat_sim.CameraSensorSpec()
        depth_sensor.uuid = "depth_sensor"
        depth_sensor.sensor_type = habitat_sim.SensorType.DEPTH
        depth_sensor.resolution = [480, 640]
        depth_sensor.position = [0.0, 1.2, 0.0]
        agent_cfg.sensor_specifications.append(depth_sensor)
        semantic_sensor = habitat_sim.CameraSensorSpec()
        semantic_sensor.uuid = "semantic_sensor"
        semantic_sensor.sensor_type = habitat_sim.SensorType.SEMANTIC
        semantic_sensor.resolution = [480, 640]
        semantic_sensor.position = [0.0, 1.2, 0.0]
        agent_cfg.sensor_specifications.append(semantic_sensor)
        # 2. === [æ ¸å¿ƒä¿®æ”¹] æ˜¾å¼å®šä¹‰åŠ¨ä½œç©ºé—´ (åŠ å…¥åé€€) ===
        # Habitat é»˜è®¤åªæœ‰ forward/left/rightï¼Œå¿…é¡»æ‰‹åŠ¨åŠ  backward
        action_space = {
            "move_forward": habitat_sim.agent.ActionSpec(
                "move_forward", habitat_sim.agent.ActuationSpec(amount=0.25)
            ),
            "move_backward": habitat_sim.agent.ActionSpec(
                "move_backward", habitat_sim.agent.ActuationSpec(amount=0.25)
            ),
            "turn_left": habitat_sim.agent.ActionSpec(
                "turn_left", habitat_sim.agent.ActuationSpec(amount=30.0)
            ),
            "turn_right": habitat_sim.agent.ActionSpec(
                "turn_right", habitat_sim.agent.ActuationSpec(amount=30.0)
            ),
            "stop": habitat_sim.agent.ActionSpec(
                "stop", habitat_sim.agent.ActuationSpec(amount=0.0)
            )
        }
        agent_cfg.action_space = action_space
        
        return habitat_sim.Simulator(habitat_sim.Configuration(sim_cfg, [agent_cfg]))

    def _init_llm(self, model_path: str):
        print(f"ğŸ§  [System] åŠ è½½æ¨¡å‹: {model_path}")
        
        base_model_path = "model_cache/qwen/Qwen2-VL-7B-Instruct"
        
        bnb_config = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)
        model = Qwen2VLForConditionalGeneration.from_pretrained(
            base_model_path, device_map="auto", quantization_config=bnb_config, trust_remote_code=True, local_files_only=True
        )
        
        model.load_adapter(model_path)
        print(f"âœ… [System] LoRA é€‚é…å™¨å·²åŠ è½½: {model_path}")
        
        processor = AutoProcessor.from_pretrained(base_model_path, min_pixels=256*28*28, max_pixels=1280*28*28, local_files_only=True)
        return model, processor

    def set_agent_state(self, position, rotation=None):
        """å¼ºåˆ¶è®¾ç½® Agent ä½ç½®"""
        agent = self.simulator.get_agent(0)
        state = habitat_sim.AgentState()
        state.position = position
        if rotation is not None:
            state.rotation = rotation
        agent.set_state(state)
        print(f"ğŸ“ [ç³»ç»Ÿ] Agent å·²é‡ç½®åˆ°åæ ‡: {position}")
    
    def _extract_objects_from_reasoning(self, reasoning: str) -> List[str]:
        """ä»LLMæ¨ç†ä¸­æå–çœ‹åˆ°çš„ç‰©ä½“"""
        objects = []
        reasoning_lower = reasoning.lower()
        
        # å®šä¹‰å¸¸è§ç‰©ä½“å…³é”®è¯
        object_keywords = {
            'lamp': ['lamp', 'light', 'lampshade', 'lighting'],
            'table': ['table', 'desk', 'surface'],
            'chair': ['chair', 'seat', 'stool'],
            'sofa': ['sofa', 'couch', 'settee'],
            'bed': ['bed', 'mattress'],
            'door': ['door', 'doorway', 'entrance'],
            'window': ['window', 'glass'],
            'wall': ['wall', 'corner'],
            'floor': ['floor', 'ground'],
            'ceiling': ['ceiling'],
            'shelf': ['shelf', 'bookshelf', 'cabinet'],
            'plant': ['plant', 'flower', 'tree'],
            'picture': ['picture', 'painting', 'art', 'frame'],
            'tv': ['tv', 'television', 'screen'],
            'carpet': ['carpet', 'rug'],
        }
        
        # æ£€æŸ¥æ¨ç†ä¸­æ˜¯å¦åŒ…å«è¿™äº›å…³é”®è¯
        for object_name, keywords in object_keywords.items():
            for keyword in keywords:
                if keyword in reasoning_lower:
                    if object_name not in objects:
                        objects.append(object_name)
                    break
        
        return objects
    
    def _get_lamp_position_in_view(self, reasoning: str) -> Optional[str]:
        """
        ä»æ¨ç†æ–‡æœ¬ä¸­æå– lamp åœ¨ç”»é¢ä¸­çš„ä½ç½®
        
        Returns:
            "left", "right", "center", æˆ– None
        """
        reasoning_lower = reasoning.lower()
        
        # æ£€æµ‹ä½ç½®å…³é”®è¯
        left_keywords = ["left side", "left of", "on the left", "to the left"]
        right_keywords = ["right side", "right of", "on the right", "to the right"]
        center_keywords = ["center", "middle", "front", "directly ahead"]
        
        for keyword in center_keywords:
            if keyword in reasoning_lower:
                return "center"
        
        for keyword in left_keywords:
            if keyword in reasoning_lower:
                return "left"
        
        for keyword in right_keywords:
            if keyword in reasoning_lower:
                return "right"
        
        return None
    
    def _get_current_yaw(self) -> float:
        """
        è·å–å½“å‰æœå‘è§’åº¦ï¼ˆåº¦æ•°ï¼‰
        
        Returns:
            float: å½“å‰æœå‘è§’åº¦ï¼ˆ0-360ï¼‰
        """
        try:
            agent_state = self.simulator.get_agent(0).get_state()
            rotation = np.array(agent_state.rotation)
            
            # å¦‚æœæ˜¯æ ‡é‡ï¼Œç›´æ¥è¿”å›
            if rotation.shape == ():
                yaw_degrees = float(rotation)
                if abs(yaw_degrees) > 10:
                    yaw_degrees = np.degrees(yaw_degrees)
                if yaw_degrees < 0:
                    yaw_degrees += 360
                if yaw_degrees >= 360:
                    yaw_degrees -= 360
                return yaw_degrees
            else:
                return 0.0
        except:
            return 0.0
    
    def _find_unexplored_position(self, current_pos: np.ndarray) -> Optional[np.ndarray]:
        """
        æ‰¾åˆ°æœªæ¢ç´¢çš„åŒºåŸŸ
        
        Args:
            current_pos: å½“å‰ä½ç½® [x, y, z]
        
        Returns:
            Optional[np.ndarray]: æœªæ¢ç´¢åŒºåŸŸçš„ä½ç½®ï¼Œæˆ– None
        """
        # åœ¨å½“å‰ä½ç½®å‘¨å›´ç”Ÿæˆå€™é€‰ç‚¹
        candidates = []
        
        # åœ¨ä¸åŒæ–¹å‘ç”Ÿæˆå€™é€‰ç‚¹ï¼ˆè·ç¦» 2-4mï¼‰
        for dx in [-3, -2, 2, 3]:
            for dz in [-3, -2, 2, 3]:
                candidate = current_pos + np.array([dx, 0, dz])
                
                # æ£€æŸ¥æ˜¯å¦åœ¨åœºæ™¯è¾¹ç•Œå†…
                if -10 <= candidate[0] <= 10 and -10 <= candidate[2] <= 10:
                    # æ£€æŸ¥æ˜¯å¦è®¿é—®è¿‡
                    rounded_candidate = (np.round(candidate[0] * 2) / 2, np.round(candidate[1] * 2) / 2, np.round(candidate[2] * 2) / 2)
                    
                    if rounded_candidate not in self.visited_positions:
                        candidates.append(candidate)
        
        # å¦‚æœæœ‰æœªæ¢ç´¢çš„åŒºåŸŸï¼Œè¿”å›è·ç¦»æœ€è¿‘çš„ä¸€ä¸ª
        if candidates:
            distances = [np.linalg.norm(c - current_pos) for c in candidates]
            best_idx = np.argmin(distances)
            return candidates[best_idx]
        
        return None
    
    def _get_position_info(self, position: np.ndarray, rotation: np.ndarray) -> Dict[str, str]:
        """
        è®¡ç®—æœå‘ä¿¡æ¯
        
        Args:
            position: ä½ç½®åæ ‡ [x, y, z]
            rotation: æ—‹è½¬è§’åº¦ï¼ˆå¼§åº¦æˆ–åº¦æ•°ï¼‰
        
        Returns:
            Dict: åŒ…å«æœå‘ä¿¡æ¯
        """
        # æå–ä½ç½®åæ ‡
        x, y, z = position[0], position[1], position[2]
        
        # è®¡ç®—æœå‘ï¼ˆåŸºäºæ—‹è½¬è§’åº¦ï¼‰
        # rotation å¯èƒ½æ˜¯æ ‡é‡ï¼ˆå¼§åº¦æˆ–åº¦æ•°ï¼‰
        try:
            # å°è¯•è½¬æ¢ä¸º numpy æ•°ç»„
            rotation_array = np.array(rotation)
            
            # è°ƒè¯•ä¿¡æ¯ï¼šæ‰“å° rotation çš„å½¢çŠ¶
            print(f"ğŸ” [è°ƒè¯•] rotation ç±»å‹: {type(rotation)}, shape: {rotation_array.shape if hasattr(rotation_array, 'shape') else 'N/A'}, size: {rotation_array.size if hasattr(rotation_array, 'size') else 'N/A'}")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ ‡é‡ï¼ˆshape ä¸ºç©ºï¼‰
            if rotation_array.shape == ():
                # rotation æ˜¯æ ‡é‡ï¼Œå¯èƒ½æ˜¯ quaternion å¯¹è±¡
                # ç®€åŒ–å¤„ç†ï¼šç›´æ¥è¿”å› 0.0 ä½œä¸ºé»˜è®¤å€¼
                # TODO: åç»­å¯ä»¥æ·»åŠ æ›´ç²¾ç¡®çš„ quaternion å¤„ç†
                yaw_degrees = 0.0
                
                # è¿”å›å®Œæ•´ä¿¡æ¯ï¼ˆä¸è½¬æ¢æœå‘æè¿°ï¼‰
                return {
                    'facing': f"{yaw_degrees:.1f}Â°",
                    'yaw': yaw_degrees,
                    'position': f"({x:.2f}, {y:.2f}, {z:.2f})"
                }
            
            # æ£€æŸ¥æ•°ç»„å½¢çŠ¶
            elif rotation_array.size >= 4:
                # è·å–å››å…ƒæ•°çš„ 4 ä¸ªåˆ†é‡
                if rotation_array.ndim == 1:
                    w, qx, qy, qz = rotation_array[0], rotation_array[1], rotation_array[2], rotation_array[3]
                elif rotation_array.ndim == 2 and rotation_array.shape[1] >= 4:
                    w, qx, qy, qz = rotation_array[0, 0], rotation_array[0, 1], rotation_array[0, 2], rotation_array[0, 3]
                elif rotation_array.ndim == 2 and rotation_array.shape[0] >= 4:
                    w, qx, qy, qz = rotation_array[0], rotation_array[1], rotation_array[2], rotation_array[3]
                else:
                    # æ ¼å¼ä¸å¯¹ï¼Œè¿”å›é»˜è®¤å€¼
                    return {
                        'facing': 'æœªçŸ¥',
                        'yaw': 0.0,
                        'position': f"({x:.2f}, {y:.2f}, {z:.2f})"
                    }
                
                # è®¡ç®— yaw è§’åº¦
                siny_cosp = 2 * (w * qz + qx * qy)
                cosy_cosp = 1 - 2 * (qy * qy + qz * qz)
                yaw = np.arctan2(siny_cosp, cosy_cosp)
                yaw_degrees = np.degrees(yaw)
                
                # å½’ä¸€åŒ–åˆ° 0-360 åº¦
                if yaw_degrees < 0:
                    yaw_degrees += 360
                
                # è½¬æ¢ä¸ºæœå‘æè¿°
                if 337.5 <= yaw_degrees or yaw_degrees < 22.5:
                    facing = "åŒ—"
                elif 22.5 <= yaw_degrees < 67.5:
                    facing = "ä¸œåŒ—"
                elif 67.5 <= yaw_degrees < 112.5:
                    facing = "ä¸œ"
                elif 112.5 <= yaw_degrees < 157.5:
                    facing = "ä¸œå—"
                elif 157.5 <= yaw_degrees < 202.5:
                    facing = "å—"
                elif 202.5 <= yaw_degrees < 247.5:
                    facing = "è¥¿å—"
                elif 247.5 <= yaw_degrees < 292.5:
                    facing = "è¥¿"
                else:
                    facing = "è¥¿åŒ—"
                
                # è¿”å›å®Œæ•´ä¿¡æ¯
                return {
                    'facing': facing,
                    'yaw': yaw_degrees,
                    'position': f"({x:.2f}, {y:.2f}, {z:.2f})"
                }
            else:
                # æ•°ç»„å¤§å°ä¸å¤Ÿï¼Œè¿”å›é»˜è®¤å€¼
                return {
                    'facing': 'æœªçŸ¥',
                    'yaw': 0.0,
                    'position': f"({x:.2f}, {y:.2f}, {z:.2f})"
                }
        except Exception as e:
            # å¦‚æœè½¬æ¢å¤±è´¥ï¼Œè¿”å›é»˜è®¤å€¼
            print(f"âš ï¸ [æœå‘è®¡ç®—å¤±è´¥] é”™è¯¯: {e}")
            return {
                'facing': 'æœªçŸ¥',
                'yaw': 0.0,
                'position': f"({x:.2f}, {y:.2f}, {z:.2f})"
            }
    
    def _evaluate_execution_result(self, action: str, dist_front: float, reasoning: str) -> str:
        """è¯„ä¼°åŠ¨ä½œæ‰§è¡Œç»“æœ"""
        if action == "stop":
            # å¦‚æœæ˜¯åœæ­¢åŠ¨ä½œï¼Œæ£€æŸ¥æ˜¯å¦çœŸçš„æ‰¾åˆ°äº†ç›®æ ‡
            if any(keyword in reasoning.lower() for keyword in ["lamp", "target", "found"]):
                return "success"
            else:
                return "partial"
        elif action == "move_forward":
            # å¦‚æœæ˜¯å‰è¿›åŠ¨ä½œï¼Œæ£€æŸ¥æ˜¯å¦æˆåŠŸç§»åŠ¨
            if dist_front > 0.5:  # å¦‚æœå‰æ–¹è·ç¦»æ­£å¸¸ï¼Œè¯´æ˜æˆåŠŸç§»åŠ¨
                return "success"
            else:
                return "failure"  # å¯èƒ½æ’å¢™äº†
        elif "turn" in action:
            # è½¬å‘åŠ¨ä½œé€šå¸¸æ˜¯æˆåŠŸçš„ï¼ˆé¿å…æ’å¢™ï¼‰
            return "success"
        elif action == "move_backward":
            # åé€€åŠ¨ä½œä¹Ÿæ˜¯æˆåŠŸçš„ï¼ˆé¿å…æ’å¢™ï¼‰
            return "success"
        else:
            return "partial"

    def run(self, instruction_text: str, target_pos: List[float] = None):
        print(f"\n{'='*20} ä»»åŠ¡å¼€å§‹ (å¤šè§†è§’æ ¡éªŒ + è‡ªä¸»å†³ç­–ç‰ˆ) {'='*20}")
        save_dir = "guocheng"
        if not os.path.exists(save_dir): 
            os.makedirs(save_dir)
        else:
            for f in os.listdir(save_dir):
                if f.endswith(".jpg"): os.remove(os.path.join(save_dir, f))

        # === åˆ›å»ºæ—¥å¿—æ–‡ä»¶ï¼ˆæ¯æ¬¡è¿è¡Œéƒ½è¦†ç›–ï¼‰===
        log_file = os.path.join(save_dir, "navigation_log.txt")
        if os.path.exists(log_file):
            os.remove(log_file)  # åˆ é™¤æ—§æ—¥å¿—æ–‡ä»¶
        log_entries = []
        
        # å†™å…¥æ—¥å¿—æ–‡ä»¶å¤´
        with open(log_file, 'w', encoding='utf-8') as f:
            f.write(f"Navigation Log - {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Task: Find LAMP\n")
            f.write(f"{'='*60}\n")
        
        self.loop_controller.reset()
        self.memory_mod.memory.clear()
        
        # === æ ¸å¿ƒå˜é‡åˆå§‹åŒ– ===
        success = False 
        self.verified = False  # è§†è§’éªŒè¯çŠ¶æ€ä½
        self.centered = False  # å±…ä¸­è°ƒæ•´çŠ¶æ€ä½
        self.consecutive_wall_hits = 0  # è¿ç»­æ’å¢™è®¡æ•°å™¨
        self.last_wall_direction = None  # ä¸Šæ¬¡æ’å¢™çš„æ–¹å‘
        self.lamp_position = None  # lamp ä½ç½®è®°å¿†
        self.lamp_found_step = None  # æ‰¾åˆ° lamp çš„æ­¥æ•°
        self.lamp_confirmed = False  # lamp æ˜¯å¦å·²ç¡®è®¤
        
        # å·²æ¢ç´¢åŒºåŸŸè®°å¿†
        self.visited_positions = []  # è®°å½•è®¿é—®è¿‡çš„ä½ç½®
        self.current_region = None  # å½“å‰åŒºåŸŸ
        self.region_visit_count = {}  # åŒºåŸŸè®¿é—®è®¡æ•°
        self.same_view_count = 0  # åŒä¸€ç”»é¢è¿ç»­å‡ºç°æ¬¡æ•°
        
        start_state = self.simulator.get_agent(0).get_state()
        start_pos = start_state.position
        prev_pos = np.array(start_pos)
        room_anchor_pos = np.array(start_pos) 
        
        while self.loop_controller.should_continue():
            current_step = self.loop_controller.current_step
            self.loop_controller.advance_step()
            
            # 1. ç¯å¢ƒæ„ŸçŸ¥
            agent_state = self.simulator.get_agent(0).get_state()
            current_pos = np.array(agent_state.position)
            perception = self.perception_mod.perceive(agent_state)
            dist_front = perception.get("depth", 999.0)
            
            if perception["image"]:
                perception["image"].save(os.path.join(save_dir, f"step_{current_step:03d}.jpg"))
            
            # 2. çŠ¶æ€ç›‘æµ‹
            move_dist = np.linalg.norm(current_pos - prev_pos)
            is_stuck = (move_dist < 0.05 and current_step > 0)
            prev_pos = current_pos
            
            # 3. å¤§è„‘æ€è€ƒ
            think_result = self.alignment_mod.think(
                perception=perception, 
                instruction=instruction_text,
                memory=self.memory_mod.retrieve(k=5),
                collision_warning=is_stuck, 
                step_count=current_step
            )
            
            reasoning = think_result.get("reasoning", "")
            reasoning_lower = reasoning.lower()
            action = self.decision_mod.decide(think_result, perception["image"])
            
            # === [é‡å¤æ¢ç´¢æ£€æµ‹] ===
            # å¦‚æœæ­£åœ¨æ¥è¿‘ lampï¼ˆæ¨ç†ä¸­æåˆ° lamp æˆ– visibleï¼‰ï¼Œè·³è¿‡é‡å¤æ¢ç´¢æ£€æµ‹
            is_approaching_lamp = any(w in reasoning_lower for w in ["lamp", "visible", "clearly visible"])
            
            # === [æ™ºèƒ½æ¢ç´¢ï¼šä½ç½®å˜åŒ–æ£€æµ‹] ===
            # è®°å½•å½“å‰ä½ç½®
            self.position_history.append(current_pos.copy())
            
            # æ£€æµ‹ä½ç½®å˜åŒ–ï¼ˆx æˆ– z å˜åŒ–å°äº 0.2ï¼‰
            if self.last_position is not None:
                # ä¸æ˜¯ç¬¬ä¸€æ¬¡å¾ªç¯ï¼Œè®¡ç®—ä½ç½®å˜åŒ–
                pos_change = np.linalg.norm(current_pos - self.last_position)
                
                # å¦‚æœæ²¡æœ‰çœ‹åˆ° lamp ä¸”ä½ç½®å˜åŒ–å°äº 0.2
                if not is_approaching_lamp and pos_change < 0.2:
                    self.position_stuck_count += 1
                    print(f"ğŸ” [æ™ºèƒ½æ¢ç´¢] ä½ç½®å˜åŒ–: {pos_change:.3f}m, å¡ä½è®¡æ•°: {self.position_stuck_count}")
                    
                    # å¦‚æœè¿ç»­ 2 æ¬¡ä½ç½®å˜åŒ–å°äº 0.2ï¼Œå‰å¾€æœªæ¢ç´¢åŒºåŸŸ
                    if self.position_stuck_count >= 2:
                        print("ğŸ§­ [æ™ºèƒ½æ¢ç´¢] æ£€æµ‹åˆ°å¡ä½ï¼Œå‰å¾€æœªæ¢ç´¢åŒºåŸŸ...")
                        
                        # å¯»æ‰¾æœªæ¢ç´¢çš„åŒºåŸŸ
                        unexplored_pos = self._find_unexplored_position(current_pos)
                        
                        if unexplored_pos is not None:
                            # è®¡ç®—è½¬å‘è§’åº¦
                            target_direction = unexplored_pos - current_pos
                            target_yaw = np.arctan2(target_direction[0], target_direction[2])
                            current_yaw = np.radians(self._get_current_yaw())
                            
                            # è®¡ç®—éœ€è¦è½¬å‘çš„è§’åº¦
                            turn_angle = target_yaw - current_yaw
                            if turn_angle > np.pi:
                                turn_angle -= 2 * np.pi
                            elif turn_angle < -np.pi:
                                turn_angle += 2 * np.pi
                            
                            # è½¬å‘åˆ°ç›®æ ‡æ–¹å‘
                            turn_steps = int(abs(turn_angle) / (np.pi / 6))  # 30Â° = Ï€/6
                            print(f"ğŸ§­ [æ™ºèƒ½æ¢ç´¢] è½¬å‘ {np.degrees(turn_angle):.1f}Â° ({turn_steps} æ­¥)...")
                            for _ in range(turn_steps):
                                if turn_angle > 0:
                                    self.execution_mod.execute("turn_left")
                                else:
                                    self.execution_mod.execute("turn_right")
                            
                            self.position_stuck_count = 0
                        else:
                            print("âš ï¸ [æ™ºèƒ½æ¢ç´¢] æœªæ‰¾åˆ°æœªæ¢ç´¢åŒºåŸŸï¼Œéšæœºè½¬å‘...")
                            # åŒå‘æ—‹è½¬ï¼šå¦‚æœä¸Šæ¬¡è½¬å‘è¿‡ï¼Œç»§ç»­åŒæ–¹å‘
                            if self.last_turn_direction is not None:
                                turn_action = self.last_turn_direction
                                print(f"ğŸ”„ [æ™ºèƒ½æ¢ç´¢] åŒå‘æ—‹è½¬å‘ {turn_action} è½¬å‘...")
                                # è®°å½•åˆ°æ—¥å¿—
                                with open(log_file, 'a', encoding='utf-8') as f:
                                    f.write(f"ğŸ”„ [æ™ºèƒ½æ¢ç´¢] åŒå‘æ—‹è½¬å‘ {turn_action} è½¬å‘...\n")
                            else:
                                turn_action = "turn_left"
                                self.last_turn_direction = turn_action
                                print(f"ğŸ”„ [æ™ºèƒ½æ¢ç´¢] éšæœºè½¬å‘ {turn_action}...")
                                # è®°å½•åˆ°æ—¥å¿—
                                with open(log_file, 'a', encoding='utf-8') as f:
                                    f.write(f"ğŸ”„ [æ™ºèƒ½æ¢ç´¢] éšæœºè½¬å‘ {turn_action}...\n")
                            self.execution_mod.execute(turn_action)
                            self.position_stuck_count = 0
                else:
                    self.position_stuck_count = 0
            
            self.last_position = current_pos
            
            # === [é‡å¤æ¢ç´¢æ£€æµ‹] ===
            if not is_approaching_lamp:
                # è®°å½•å½“å‰ä½ç½®ï¼ˆå››èˆäº”å…¥åˆ° 0.5m ç²¾åº¦ï¼‰
                rounded_pos = (np.round(current_pos[0] * 2) / 2, np.round(current_pos[1] * 2) / 2, np.round(current_pos[2] * 2) / 2)
                
                # æ£€æŸ¥æ˜¯å¦è®¿é—®è¿‡è¿™ä¸ªä½ç½®
                if rounded_pos in self.visited_positions:
                    self.same_view_count += 1
                    print(f"âš ï¸ [é‡å¤æ¢ç´¢] æ£€æµ‹åˆ°å·²è®¿é—®ä½ç½® {rounded_pos}ï¼Œè¿ç»­æ¬¡æ•°: {self.same_view_count}")
                    
                    # å¦‚æœåŒä¸€ä½ç½®è¿ç»­å‡ºç°è¶…è¿‡ 2 æ¬¡ï¼Œå¼ºåˆ¶è½¬å‘
                    if self.same_view_count >= 2:
                        print("ğŸ”„ [å¼ºåˆ¶è½¬å‘] é‡å¤æ¢ç´¢è¿‡å¤šï¼Œæ‰§è¡Œ 180Â° è½¬å‘ï¼")
                        # åŒå‘æ—‹è½¬ï¼šå¦‚æœä¸Šæ¬¡è½¬å‘è¿‡ï¼Œç»§ç»­åŒæ–¹å‘
                        if self.last_turn_direction is not None:
                            turn_action = self.last_turn_direction
                            print(f"ğŸ”„ [å¼ºåˆ¶è½¬å‘] åŒå‘æ—‹è½¬å‘ {turn_action} è½¬å‘...")
                            # è®°å½•åˆ°æ—¥å¿—
                            with open(log_file, 'a', encoding='utf-8') as f:
                                f.write(f"ğŸ”„ [å¼ºåˆ¶è½¬å‘] åŒå‘æ—‹è½¬å‘ {turn_action} è½¬å‘...\n")
                        else:
                            turn_action = "turn_left"
                            self.last_turn_direction = turn_action
                            print(f"ğŸ”„ [å¼ºåˆ¶è½¬å‘] éšæœºè½¬å‘ {turn_action}...")
                            # è®°å½•åˆ°æ—¥å¿—
                            with open(log_file, 'a', encoding='utf-8') as f:
                                f.write(f"ğŸ”„ [å¼ºåˆ¶è½¬å‘] éšæœºè½¬å‘ {turn_action}...\n")
                        for _ in range(6):  # 180Â°
                            self.execution_mod.execute(turn_action)
                        self.same_view_count = 0
                        # æ›´æ–°ä½ç½®
                        agent_state = self.simulator.get_agent(0).get_state()
                        current_pos = np.array(agent_state.position)
                        prev_pos = current_pos
                else:
                    self.same_view_count = 0
                    self.visited_positions.append(rounded_pos)
                
                # é™åˆ¶è®°å¿†å¤§å°ï¼Œåªä¿ç•™æœ€è¿‘ 100 ä¸ªä½ç½®
                if len(self.visited_positions) > 100:
                    self.visited_positions = self.visited_positions[-100:]

            # --- [é•¿æœŸè®°å¿†] æˆ¿é—´æ‰“è½¬æ£€æµ‹ ---
            if current_step % 30 == 0:
                dist_from_anchor = np.linalg.norm(current_pos - room_anchor_pos)
                if dist_from_anchor < 1.5: 
                    print(f"ğŸ§  [é•¿æœŸè®°å¿†] è­¦å‘Šï¼šå·²åœ¨å½“å‰åŒºåŸŸé€—ç•™ï¼Œå¼ºåˆ¶é€ƒé€¸ã€‚")
                    for _ in range(3): self.execution_mod.execute("turn_right")
                room_anchor_pos = current_pos 

            # 4. è§†è§‰æ¯”é‡è§£æ
            import re
            bbox_match = re.search(r'\[(\d+),\s*(\d+),\s*(\d+),\s*(\d+)\]', reasoning)
            area_ratio = 0.0
            if bbox_match:
                coords = [int(c) for c in bbox_match.groups()]
                area_ratio = ((coords[2] - coords[0]) * (coords[3] - coords[1])) / 1_000_000.0
            
            # 5. === [æ ¸å¿ƒä¿®æ”¹ï¼šå¤šè§†è§’åŠ¨æ€æ ¡éªŒ + å±…ä¸­è°ƒæ•´] ===
            # ä¸å†å¼ºåˆ¶çº¦æŸ 'lamp' å…³é”®å­—ï¼Œåªè¦æ¨¡å‹æƒ³ stopï¼Œç³»ç»Ÿå°±å¯åŠ¨æ ¡éªŒ
            print(f"ğŸ” [è°ƒè¯•] action: {action}, verified: {self.verified}, centered: {self.centered}")
            
            if action == "stop":
                if not self.verified:
                    # ç¬¬ä¸€æ¬¡ç¡®è®¤ï¼šæ£€æŸ¥æ¨ç†ä¸­æ˜¯å¦æ˜ç¡®è¯´lampå¯è§
                    if "the lamp is visible in the current view" in reasoning_lower or "the lamp is clearly visible in the center of the image" in reasoning_lower:
                        # ç›´æ¥å‘å‰èµ°ä¸‰æ­¥ï¼ˆæ¯æ­¥0.75ç±³ï¼‰
                        print("ğŸ¯ [æ¥è¿‘ç›®æ ‡] Lampå·²ç¡®è®¤å¯è§ï¼Œç›´æ¥å‘å‰èµ°ä¸‰æ­¥...")
                        for i in range(3):
                            # è·å–æ–°çš„æ„ŸçŸ¥
                            agent_state = self.simulator.get_agent(0).get_state()
                            perception = self.perception_mod.perceive(agent_state)
                            
                            # ä¿å­˜å›¾åƒ
                            if perception["image"]:
                                perception["image"].save(os.path.join(save_dir, f"step_{current_step + i + 1:03d}.jpg"))
                            
                            # è·å–ä½ç½®å’Œæœå‘ä¿¡æ¯
                            position_info = self._get_position_info(
                                np.array(agent_state.position),
                                np.array(agent_state.rotation)
                            )
                            
                            # è®°å½•åˆ°æ—¥å¿—
                            with open(log_file, 'a', encoding='utf-8') as f:
                                f.write(f"\n{'='*60}\n")
                                f.write(f"Step: {current_step + i + 1}\n")
                                f.write(f"{'-'*60}\n")
                                f.write(f"ğŸ“ ä½ç½®: {position_info['position']}\n")
                                
                                # 1. ä»æ¨ç†ä¸­æå–è§‚æµ‹åˆ°çš„ç‰©ä½“ï¼ˆä¸æ˜¾ç¤ºï¼‰
                                detected_objects = self._extract_objects_from_reasoning(reasoning)
                                
                                # 2. æ¨ç†è¿‡ç¨‹
                                f.write(f"ğŸ§  æ¨ç†: {reasoning}\n")
                                
                                # 3. æ‰§è¡ŒåŠ¨ä½œ
                                f.write(f"ğŸ¯ åŠ¨ä½œ: move_forward\n")
                                f.write(f"{'='*60}\n")
                            
                            # æ‰§è¡Œmove_forward
                            self.execution_mod.execute("move_forward")
                            self.memory_mod.store(perception, "move_forward")
                        
                        # === [ä¿®å¤] ä»»åŠ¡ç»“æŸæ—¶è®°å½• stop ä½œä¸ºç»“å°¾ ===
                        with open(log_file, 'a', encoding='utf-8') as f:
                            f.write(f"\n{'='*60}\n")
                            f.write(f"Step: {current_step + 3}_end\n")
                            f.write(f"{'-'*60}\n")
                            f.write(f"ğŸ§  æ¨ç†: Task completed - target found and approached\n")
                            f.write(f"ğŸ¯ åŠ¨ä½œ: stop (ä»»åŠ¡ç»“æŸ)\n")
                            f.write(f"{'='*60}\n")
                        
                        # === [ä¿®å¤] äºŒæ¬¡ç¡®è®¤æˆåŠŸåï¼Œæ ‡è®°ä»»åŠ¡æˆåŠŸå¹¶ç”Ÿæˆæ–‡ä»¶ ===
                        success = True
                        final_dist = 0.0
                        self.memory_mod.set_last_result("success")
                        print("ğŸ¯ [è®°å¿†å¢å¼º] ä»»åŠ¡æˆåŠŸï¼æ‰¾åˆ°å°ç¯å¹¶æ¥è¿‘ã€‚")
                        self.memory_mod.export_memory(f"successful_navigation_step_{current_step}.json")
                        
                        # === ä¿å­˜å®Œæ•´æ—¥å¿— ===
                        with open(log_file, 'a', encoding='utf-8') as f:
                            f.write(f"\n{'='*60}\n")
                            f.write(f"{'='*60} ä»»åŠ¡å®Œæˆ {'='*60}\n")
                            f.write(f"æˆåŠŸçŠ¶æ€: {success}\n")
                            f.write(f"è¯†åˆ«æ­¥æ•°: {current_step}\n")
                            f.write(f"{'='*60}\n")
                        
                        break  # é€€å‡ºå¾ªç¯ï¼Œç»“æŸä»»åŠ¡
                    else:
                        # è®°å½• lamp ä½ç½®ï¼Œä¸è½¬å‘
                        print("ğŸ•µï¸ [ä¸»åŠ¨è§‚æµ‹] ç–‘ä¼¼å‘ç°ç›®æ ‡ï¼Œè®°å½•ä½ç½®å¹¶ç»§ç»­å‰è¿›...")
                        self.verified = True
                        # ä¸æ‰§è¡Œè½¬å‘ï¼Œç›´æ¥ç»§ç»­å‰è¿›æ¥è¿‘ lamp
                        # è¿™æ ·å¯ä»¥é¿å… lamp è·‘å‡ºè§†é‡
                        # å­˜å‚¨è¿™ä¸€æ­¥åŠ¨ä½œå¹¶è·³è¿‡æœ¬æ¬¡å¾ªç¯ï¼Œç­‰å¾…ä¸‹ä¸€å¸§ï¼ˆæ–°è§†è§’ï¼‰çš„æ€è€ƒ
                        self.memory_mod.store(perception, "move_forward")
                        continue
                elif self.verified and not self.centered:
                    # ç¬¬äºŒæ¬¡ç¡®è®¤ï¼šå…ˆè°ƒæ•´ lamp åˆ°ç”»é¢ä¸­å¤®
                    lamp_position = self._get_lamp_position_in_view(reasoning)
                    
                    if lamp_position == "left":
                        print("ğŸ¯ [å±…ä¸­è°ƒæ•´] Lamp åœ¨å·¦ä¾§ï¼Œå‘å³è°ƒæ•´...")
                        self.execution_mod.execute("turn_right")
                    elif lamp_position == "right":
                        print("ğŸ¯ [å±…ä¸­è°ƒæ•´] Lamp åœ¨å³ä¾§ï¼Œå‘å·¦è°ƒæ•´...")
                        self.execution_mod.execute("turn_left")
                    elif lamp_position == "center":
                        print("âœ… [å±…ä¸­è°ƒæ•´] Lamp å·²åœ¨ä¸­å¤®ï¼Œå‡†å¤‡æ¥è¿‘...")
                        self.centered = True
                    else:
                        print("âš ï¸ [å±…ä¸­è°ƒæ•´] æ— æ³•ç¡®å®š lamp ä½ç½®ï¼Œé»˜è®¤å±…ä¸­...")
                        self.centered = True
                    
                    # å­˜å‚¨è¿™ä¸€æ­¥åŠ¨ä½œå¹¶è·³è¿‡æœ¬æ¬¡å¾ªç¯
                    self.memory_mod.store(perception, action)
                    continue
            
            # å¦‚æœæ‰§è¡Œäº†ç§»åŠ¨æˆ–è½¬å‘åŠ¨ä½œï¼Œé‡ç½®æ ¡éªŒçŠ¶æ€
            # æ³¨æ„ï¼šç‰©ç†æ‹¦æˆªï¼ˆæ’å¢™ï¼‰ä¸ç®—çœŸæ­£çš„ç§»åŠ¨ï¼Œä¸åº”è¯¥é‡ç½® verified
            if ("move" in action or "turn" in action) and dist_front >= 0.35:
                self.verified = False

            # 6. ç‰©ç†é¿éšœæ‹¦æˆª (ä¼˜å…ˆçº§æœ€é«˜)
            if action == "move_forward" and dist_front < 0.5:
                self.consecutive_wall_hits += 1
                print(f"ğŸ›¡ï¸ [ç‰©ç†æ‹¦æˆª] è·ç¦»è¿‡è¿‘({dist_front:.2f}m)ï¼Œè¿ç»­æ’å¢™ {self.consecutive_wall_hits} æ¬¡ã€‚")
                
                # å¦‚æœè¿ç»­æ’å¢™è¶…è¿‡ 3 æ¬¡ï¼Œå¼ºåˆ¶æ‰§è¡Œå¤§è§’åº¦è½¬å‘
                if self.consecutive_wall_hits >= 3:
                    print("ğŸ”„ [å¼ºåˆ¶è½¬å‘] è¿ç»­æ’å¢™è¿‡å¤šï¼Œæ‰§è¡Œ 180Â° è½¬å‘é€ƒé€¸ï¼")
                    # åŒå‘æ—‹è½¬ï¼šå¦‚æœä¸Šæ¬¡è½¬å‘è¿‡ï¼Œç»§ç»­åŒæ–¹å‘
                    if self.last_turn_direction is not None:
                        turn_action = self.last_turn_direction
                        print(f"ğŸ”„ [ç‰©ç†æ‹¦æˆª] åŒå‘æ—‹è½¬å‘ {turn_action} è½¬å‘...")
                        # è®°å½•åˆ°æ—¥å¿—
                        with open(log_file, 'a', encoding='utf-8') as f:
                            f.write(f"ğŸ”„ [ç‰©ç†æ‹¦æˆª] åŒå‘æ—‹è½¬å‘ {turn_action} è½¬å‘...\n")
                    else:
                        turn_action = "turn_left"
                        self.last_turn_direction = turn_action
                        print(f"ğŸ”„ [ç‰©ç†æ‹¦æˆª] éšæœºè½¬å‘ {turn_action}...")
                        # è®°å½•åˆ°æ—¥å¿—
                        with open(log_file, 'a', encoding='utf-8') as f:
                            f.write(f"ğŸ”„ [ç‰©ç†æ‹¦æˆª] éšæœºè½¬å‘ {turn_action}...\n")
                    for _ in range(6):  # 6 * 30Â° = 180Â°
                        self.execution_mod.execute(turn_action)
                    self.consecutive_wall_hits = 0  # é‡ç½®è®¡æ•°å™¨
                    action = "move_forward"  # è½¬å‘åç»§ç»­å‰è¿›
                else:
                    # æ™®é€šæ’å¢™ï¼Œéšæœºè½¬å‘
                    # åŒå‘æ—‹è½¬ï¼šå¦‚æœä¸Šæ¬¡è½¬å‘è¿‡ï¼Œç»§ç»­åŒæ–¹å‘
                    if self.last_turn_direction is not None:
                        action = self.last_turn_direction
                        print(f"ğŸ”„ [ç‰©ç†æ‹¦æˆª] åŒå‘æ—‹è½¬å‘ {action} è½¬å‘...")
                        # è®°å½•åˆ°æ—¥å¿—
                        with open(log_file, 'a', encoding='utf-8') as f:
                            f.write(f"ğŸ”„ [ç‰©ç†æ‹¦æˆª] åŒå‘æ—‹è½¬å‘ {action} è½¬å‘...\n")
                    else:
                        action = random.choice(["turn_left", "turn_right"])
                        self.last_turn_direction = action
                        print(f"ğŸ”„ [ç‰©ç†æ‹¦æˆª] éšæœºè½¬å‘ {action}...")
                        # è®°å½•åˆ°æ—¥å¿—
                        with open(log_file, 'a', encoding='utf-8') as f:
                            f.write(f"ğŸ”„ [ç‰©ç†æ‹¦æˆª] éšæœºè½¬å‘ {action}...\n")
                    # é¿å…è¿ç»­å‘åŒä¸€æ–¹å‘è½¬å‘
                    if self.last_wall_direction == action:
                        action = "turn_right" if action == "turn_left" else "turn_left"
                    self.last_wall_direction = action
                # ä¸é‡ç½® verifiedï¼Œå› ä¸ºæ’å¢™åä½ç½®æ²¡å˜ï¼Œåº”è¯¥ç»§ç»­ç¡®è®¤
                # self.verified = False  # æ³¨é‡Šæ‰ï¼Œé¿å…æ­»å¾ªç¯
            else:
                # æˆåŠŸå‰è¿›ï¼Œé‡ç½®æ’å¢™è®¡æ•°å™¨
                self.consecutive_wall_hits = 0

            # 7. åŠ¨ä½œæ‰§è¡Œ
            # å‡å°‘è¿›é—¨åŠ é€Ÿï¼Œåªåœ¨æ— ç›®æ ‡æ—¶åº”ç”¨
            # åªæœ‰æ˜ç¡®è¯´çœ‹åˆ° lamp æ—¶æ‰è®¤ä¸ºæœ‰ lampï¼ˆæ’é™¤ "no visible lamp" ç­‰å¦å®šè¡¨è¾¾ï¼‰
            has_lamp = any(w in reasoning_lower for w in ["lamp is visible", "lamp visible", "clearly visible lamp", "see a lamp", "found a lamp", "lamp on", "light is visible"])
            is_doorway = any(w in reasoning_lower for w in ["doorway", "opening", "enter"])
            
            # === [åŒå‘æ—‹è½¬å¼ºåˆ¶] åœ¨æ²¡æœ‰lampçš„å‰æä¸‹ï¼Œå¼ºåˆ¶è½¬å‘åŠ¨ä½œéµå¾ªåŒå‘æ—‹è½¬ ===
            if not has_lamp and action in ["turn_left", "turn_right"]:
                if self.last_turn_direction is not None:
                    # å¼ºåˆ¶æ”¹ä¸ºåŒå‘æ—‹è½¬
                    original_action = action
                    action = self.last_turn_direction
                    print(f"ğŸ”„ [åŒå‘æ—‹è½¬å¼ºåˆ¶] åŸåŠ¨ä½œ {original_action} -> æ”¹ä¸º {action}")
                    # è®°å½•åˆ°æ—¥å¿—
                    with open(log_file, 'a', encoding='utf-8') as f:
                        f.write(f"ğŸ”„ [åŒå‘æ—‹è½¬å¼ºåˆ¶] åŸåŠ¨ä½œ {original_action} -> æ”¹ä¸º {action}\n")
                else:
                    # è®°å½•è¿™æ¬¡è½¬å‘æ–¹å‘
                    self.last_turn_direction = action
                    print(f"ğŸ”„ [åŒå‘æ—‹è½¬è®°å½•] è®°å½•è½¬å‘æ–¹å‘: {action}")
                    # è®°å½•åˆ°æ—¥å¿—
                    with open(log_file, 'a', encoding='utf-8') as f:
                        f.write(f"ğŸ”„ [åŒå‘æ—‹è½¬è®°å½•] è®°å½•è½¬å‘æ–¹å‘: {action}\n")
            
            # === [æ”¹è¿›æ¢ç´¢ç­–ç•¥] æ— ç›®æ ‡æ—¶é‡‡ç”¨"éšæœºè½¬å‘ + å‰è¿›"ç»„åˆ ===
            # åœ¨æ¥è¿‘lampæ¨¡å¼ä¸‹ä¸è§¦å‘æ¢ç´¢ç­–ç•¥
            if not self.approaching_lamp and not has_lamp and action == "move_forward" and dist_front > 0.5:
                # æ¯ 3 æ­¥å¼ºåˆ¶è½¬å‘ä¸€æ¬¡ï¼Œé¿å…ä¸€ç›´èµ°ç›´çº¿
                if current_step % 3 == 0 and current_step > 0:
                    # åŒå‘æ—‹è½¬ï¼šå¦‚æœä¸Šæ¬¡è½¬å‘è¿‡ï¼Œç»§ç»­åŒæ–¹å‘
                    if self.last_turn_direction is not None:
                        action = self.last_turn_direction
                        print(f"ğŸ”„ [æ¢ç´¢ç­–ç•¥] æ— ç›®æ ‡ï¼ŒåŒå‘æ—‹è½¬å‘ {action} è½¬å‘...")
                        # è®°å½•åˆ°æ—¥å¿—
                        with open(log_file, 'a', encoding='utf-8') as f:
                            f.write(f"ğŸ”„ [æ¢ç´¢ç­–ç•¥] æ— ç›®æ ‡ï¼ŒåŒå‘æ—‹è½¬å‘ {action} è½¬å‘...\n")
                    else:
                        action = random.choice(["turn_left", "turn_right"])
                        self.last_turn_direction = action
                        print(f"ğŸ”„ [æ¢ç´¢ç­–ç•¥] æ— ç›®æ ‡ï¼Œéšæœºè½¬å‘ {action}...")
                        # è®°å½•åˆ°æ—¥å¿—
                        with open(log_file, 'a', encoding='utf-8') as f:
                            f.write(f"ğŸ”„ [æ¢ç´¢ç­–ç•¥] æ— ç›®æ ‡ï¼Œéšæœºè½¬å‘ {action}...\n")
                    self.execution_mod.execute(action)
                    # è½¬å‘åç»§ç»­å‰è¿›
                    self.execution_mod.execute("move_forward")
                elif is_doorway and dist_front > 1.2:
                    print("ğŸš€ [è¿›é—¨å¢å¼º] æ— ç›®æ ‡æ—¶åŠ é€Ÿé€šè¿‡é—¨å£...")
                    self.execution_mod.execute("move_forward")
                    self.execution_mod.execute("move_forward")
                else:
                    self.execution_mod.execute(action)
            else:
                # å¦‚æœæœ‰lampæˆ–æ­£åœ¨æ¥è¿‘lampï¼Œé‡ç½®è½¬å‘æ–¹å‘
                if has_lamp or self.approaching_lamp:
                    self.last_turn_direction = None
                self.execution_mod.execute(action)
            
            # === è®°å½•æ—¥å¿— ===
            # åªè®°å½•æ¨¡å‹çš„æ¨ç†å’ŒåŠ¨ä½œï¼Œä¸åŒ…å«æç¤ºè¯
            # è·å–æ–¹ä½å’Œæœå‘ä¿¡æ¯
            agent_state = self.simulator.get_agent(0).get_state()
            position_info = self._get_position_info(
                np.array(agent_state.position),
                np.array(agent_state.rotation)
            )
            
            with open(log_file, 'a', encoding='utf-8') as f:
                f.write(f"\n{'='*60}\n")
                f.write(f"Step: {current_step}\n")
                f.write(f"{'-'*60}\n")
                f.write(f"ğŸ“ ä½ç½®: {position_info['position']}\n")
                f.write(f"ğŸ‘ï¸ Yaw: {position_info['yaw']:.1f}Â°\n")
                
                # 1. ä»æ¨ç†ä¸­æå–è§‚æµ‹åˆ°çš„ç‰©ä½“ï¼ˆä¸æ˜¾ç¤ºï¼‰
                detected_objects = self._extract_objects_from_reasoning(reasoning)
                
                # 2. æ¨ç†è¿‡ç¨‹
                f.write(f"ğŸ§  æ¨ç†: {reasoning}\n")
                
                # 3. æ‰§è¡ŒåŠ¨ä½œï¼ˆè®°å½•ä¿®æ”¹åçš„åŠ¨ä½œï¼‰
                f.write(f"ğŸ¯ åŠ¨ä½œ: {action}\n")
                f.write(f"{'='*60}\n")
            
            # === [è®°å¿†å¢å¼º] æ‰§è¡Œç»“æœè¯„ä¼°å’Œè®°å¿†å­˜å‚¨ ===
            execution_result = self._evaluate_execution_result(action, dist_front, reasoning_lower)
            
            # è®¾ç½®ä¸Šä¸€æ­¥çš„ç»“æœç”¨äºé‡è¦æ€§è¯„ä¼°
            self.memory_mod.set_last_result(execution_result)
            
            # å­˜å‚¨è®°å¿†å¹¶è·å–ç‰©ä½“å…³è”ä¿¡æ¯
            memory_result = self.memory_mod.store(perception, action)
            associations = memory_result.get('associations', [])
            
            # === è®°å½•ç‰©ä½“å…³è”ä¿¡æ¯åˆ°æ—¥å¿— ===
            if associations:
                with open(log_file, 'a', encoding='utf-8') as f:
                    f.write(f"ğŸ”— [ç‰©ä½“å…³è”] æœ¬æ­¥è¯†åˆ«åˆ° {len(associations)} ä¸ªç‰©ä½“:\n")
                    for assoc in associations:
                        if assoc['is_new']:
                            f.write(f"  â• æ–°ç‰©ä½“: {assoc['object_type']} (ID: {assoc['object_id']})\n")
                        else:
                            dist_str = f", è·ç¦»ä¸Šæ¬¡ä½ç½®: {assoc['distance']:.2f}m" if assoc['distance'] else ""
                            f.write(f"  ğŸ”„ å·²çŸ¥ç‰©ä½“: {assoc['object_type']} (ID: {assoc['object_id']}){dist_str}\n")
                    f.write(f"{'='*60}\n")
            
            # å®šæœŸè®°å¿†å·©å›º
            if current_step % 50 == 0 and current_step > 0:
                self.memory_mod.consolidate_memory()
                print(f"ğŸ§  [è®°å¿†å·©å›º] ç¬¬ {current_step} æ­¥æ‰§è¡Œè®°å¿†å·©å›º")
                
                # åœ¨æ–°çš„ä½œç”¨åŸŸä¸­å†™å…¥æ—¥å¿—
                with open(log_file, 'a', encoding='utf-8') as f:
                    f.write(f"\n{'='*60}\n")
                    f.write(f"ğŸ§  [è®°å¿†å·©å›º] ç¬¬ {current_step} æ­¥æ‰§è¡Œè®°å¿†å·©å›º\n")
                    f.write(f"{'='*60}\n")

        print(f"\n{'='*20} ä»»åŠ¡ç»“æŸ {'='*20}")
        self.scoring_mod.score(
            trajectory=self.memory_mod.get_trajectory(),
            goal_reached=success,
            start_position=start_pos,
            target_position=target_pos
        )


# ============================================================================
# Main Entry Point (æ ¸å¿ƒä¿®æ”¹é€»è¾‘)
# ============================================================================
if __name__ == "__main__":
    # 1. [ä¿®æ”¹] åœºæ™¯è·¯å¾„æ¢æˆç°ä»£å…¬å¯“ (ç¡®ä¿ä½ æœ‰è¿™ä¸ªæ–‡ä»¶)
    SCENE_FILE = "data/scene_datasets/habitat-test-scenes/apartment_1.glb"
    MODEL_PATH = "saves/qwen2vl-7b-vln/lora/sft"  # ä½¿ç”¨å¾®è°ƒåçš„ LoRA æ¨¡å‹
    
    if not os.path.exists(SCENE_FILE):
        print(f"âŒ æ‰¾ä¸åˆ° apartment_1ï¼Œå°è¯•ä½¿ç”¨ apartment_0...")
        SCENE_FILE = "data/scene_datasets/habitat-test-scenes/apartment_0.glb"
        if not os.path.exists(SCENE_FILE):
            raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°åœ°å›¾æ–‡ä»¶: {SCENE_FILE}")
    
    try:
        agent = VLNAgent(scene_path=SCENE_FILE, model_path=MODEL_PATH)
        sim = agent.simulator
        pathfinder = sim.pathfinder
        
        # 2. [ä¿®æ”¹] ä½¿ç”¨å›ºå®šèµ·ç‚¹ï¼Œéšæœºæœå‘
        print("ğŸ² [System] ä½¿ç”¨å›ºå®šèµ·ç‚¹ï¼Œéšæœºæœå‘...")
        # å›ºå®šèµ·ç‚¹åæ ‡
        start_pos = [4.5, -0.8, 0.7]
        
        # éšæœºæœå‘ï¼ˆ0 åˆ° 2Ï€ å¼§åº¦ï¼‰
        random_yaw = random.uniform(0, 2 * np.pi)
        rotation = R.from_euler('YXZ', [random_yaw, 0, 0]).as_quat()
        
        agent.set_agent_state(start_pos, rotation)
        print(f"ğŸ“ èµ·ç‚¹åæ ‡: {start_pos}")
        print(f"ğŸ§­ éšæœºæœå‘: {random_yaw:.2f} å¼§åº¦ ({np.degrees(random_yaw):.1f}Â°)")

        # 3. [ç®€åŒ–] ä¸è®¾ç½®ç›®æ ‡ç‚¹ï¼Œè®©ä»£ç†è‡ªç”±æ¢ç´¢ç›´åˆ°æ‰¾åˆ°å°ç¯
        target_pos = None
        print(f"ğŸ“ [System] ä»»åŠ¡ï¼šæ¢ç´¢ç¯å¢ƒç›´åˆ°æ‰¾åˆ°å°ç¯")
        
        # 4. è¿è¡Œä»»åŠ¡
        instruction = "Find the LAMP."
        agent.run(instruction, target_pos=target_pos)
        draw_trajectory(agent, target_pos=target_pos, save_path="vln_result_with_goal.png")
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ç¨‹åºã€‚")
    except Exception as e:
        print(f"\nâŒ ç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        import traceback
        traceback.print_exc()